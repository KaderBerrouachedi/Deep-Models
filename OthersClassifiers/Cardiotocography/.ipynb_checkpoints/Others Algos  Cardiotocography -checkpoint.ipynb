{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS   ...       Min  \\\n",
       "0  146.0  0.0  0.0  5.0  65.0   0.4  33.0   7.4  0.0  0.0   ...     134.0   \n",
       "1  128.0  0.0  0.0  2.0  86.0   0.3  79.0   2.9  0.0  0.0   ...     114.0   \n",
       "2  149.0  0.0  0.0  5.0  61.0   0.4  34.0   5.6  0.0  0.0   ...     148.0   \n",
       "3  122.0  0.0  0.0  0.0  83.0   0.5   6.0  15.6  0.0  0.0   ...      62.0   \n",
       "4  134.0  0.0  4.0  0.0  79.0   0.2  42.0   5.5  0.0  0.0   ...     128.0   \n",
       "\n",
       "     Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  outlier  \n",
       "0  164.0   1.0     0.0  150.0  149.0   151.0       1.0       0.0        1  \n",
       "1  130.0   0.0     0.0  128.0  126.0   129.0       0.0       1.0        1  \n",
       "2  160.0   1.0     0.0  154.0  153.0   155.0       0.0       0.0        1  \n",
       "3  130.0   0.0     0.0  122.0  122.0   123.0       3.0       1.0        1  \n",
       "4  145.0   2.0     0.0  135.0  135.0   136.0       1.0       0.0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('Cardiotocography_02_v10.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1688, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/Cardiotocography.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,21]\n",
    "X = df[:,0:21]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:03:20,853][cascade_classifier.fit_transform] X_groups_train.shape=[(1181, 21)],y_train.shape=(1181,),X_groups_test.shape=[(507, 21)],y_test.shape=(507,)\n",
      "[ 2018-04-25 20:03:20,856][cascade_classifier.fit_transform] group_dims=[21]\n",
      "[ 2018-04-25 20:03:20,858][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-04-25 20:03:20,859][cascade_classifier.fit_transform] group_ends=[21]\n",
      "[ 2018-04-25 20:03:20,862][cascade_classifier.fit_transform] X_train.shape=(1181, 21),X_test.shape=(507, 21)\n",
      "[ 2018-04-25 20:03:20,863][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(1181, 21), X_cur_test.shape=(507, 21)\n",
      "[ 2018-04-25 20:03:21,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:03:22,315][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:03:23,110][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=99.15%\n",
      "[ 2018-04-25 20:03:23,884][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-25 20:03:24,665][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:03:25,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:03:26,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-25 20:03:27,124][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-25 20:03:27,874][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:03:28,635][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:03:28,776][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-04-25 20:03:28,778][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.44%\n",
      "[ 2018-04-25 20:03:29,431][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:03:30,256][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:03:31,070][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:03:31,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-25 20:03:32,749][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:03:33,520][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:03:34,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:03:35,144][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-25 20:03:35,946][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:03:36,744][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-25 20:03:36,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-25 20:03:36,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:03:36,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:03:37,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-25 20:03:37,055][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,082][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,107][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,128][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,174][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,198][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,223][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:03:37,224][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-25 20:03:37,226][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-25 20:03:37,228][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=98.56%\n",
      "[ 2018-04-25 20:03:37,229][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.63%\n",
      "[ 2018-04-25 20:03:37,232][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-25 20:03:37,821][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:03:38,669][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:03:39,469][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:03:40,262][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-25 20:03:41,050][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-25 20:03:41,824][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:03:42,611][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:03:43,424][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-25 20:03:44,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=99.15%\n",
      "[ 2018-04-25 20:03:45,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-25 20:03:45,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=98.73%\n",
      "[ 2018-04-25 20:03:45,311][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=97.44%\n",
      "[ 2018-04-25 20:03:46,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:03:46,830][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:03:47,617][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:03:48,407][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-25 20:03:49,169][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:03:49,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-25 20:03:50,774][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-25 20:03:51,566][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-25 20:03:52,504][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=99.15%\n",
      "[ 2018-04-25 20:03:53,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=99.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:03:53,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=98.73%\n",
      "[ 2018-04-25 20:03:53,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:03:53,531][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:03:53,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:03:53,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:03:53,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=97.46%\n",
      "[ 2018-04-25 20:03:53,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:03:53,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:03:53,723][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:03:53,751][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-25 20:03:53,782][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=99.15%\n",
      "[ 2018-04-25 20:03:53,811][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:03:53,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-25 20:03:53,814][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-25 20:03:53,816][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=98.65%\n",
      "[ 2018-04-25 20:03:53,817][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=97.63%\n",
      "[ 2018-04-25 20:03:53,819][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-25 20:03:54,442][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:03:55,206][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.46%\n",
      "[ 2018-04-25 20:03:55,979][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=99.15%\n",
      "[ 2018-04-25 20:03:56,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-25 20:03:57,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:03:58,472][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:03:59,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=97.46%\n",
      "[ 2018-04-25 20:04:00,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-25 20:04:00,845][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=99.15%\n",
      "[ 2018-04-25 20:04:01,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-25 20:04:01,857][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=98.56%\n",
      "[ 2018-04-25 20:04:01,859][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=97.44%\n",
      "[ 2018-04-25 20:04:02,530][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:04:03,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:04:04,306][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:04:05,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-25 20:04:05,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:04:06,811][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-25 20:04:07,592][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:04:08,465][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-25 20:04:09,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:04:10,142][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=99.15%\n",
      "[ 2018-04-25 20:04:10,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=98.56%\n",
      "[ 2018-04-25 20:04:10,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:04:10,353][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:04:10,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=99.15%\n",
      "[ 2018-04-25 20:04:10,450][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:04:10,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=97.46%\n",
      "[ 2018-04-25 20:04:10,529][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:04:10,575][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:04:10,610][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=99.15%\n",
      "[ 2018-04-25 20:04:10,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=98.31%\n",
      "[ 2018-04-25 20:04:10,677][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:04:10,710][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:04:10,712][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-25 20:04:10,714][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:04:10,716][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=98.56%\n",
      "[ 2018-04-25 20:04:10,717][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=97.63%\n",
      "[ 2018-04-25 20:04:10,719][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-25 20:04:11,303][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:04:12,147][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:04:12,947][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:04:13,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-25 20:04:14,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:04:15,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:04:16,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=96.61%\n",
      "[ 2018-04-25 20:04:17,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-25 20:04:17,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:04:18,720][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=98.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:04:18,868][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=98.31%\n",
      "[ 2018-04-25 20:04:18,870][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:04:19,552][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:04:20,403][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=97.46%\n",
      "[ 2018-04-25 20:04:21,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:04:22,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-25 20:04:22,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-25 20:04:23,808][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-25 20:04:24,606][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:04:25,487][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=97.46%\n",
      "[ 2018-04-25 20:04:26,289][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,088][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,240][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:04:27,298][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-04-25 20:04:27,341][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,379][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=99.15%\n",
      "[ 2018-04-25 20:04:27,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,447][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,482][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,515][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,554][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=97.46%\n",
      "[ 2018-04-25 20:04:27,584][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:04:27,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-25 20:04:27,616][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:04:27,618][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=98.39%\n",
      "[ 2018-04-25 20:04:27,619][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=97.63%\n",
      "[ 2018-04-25 20:04:27,621][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(1181, 27), X_cur_test.shape=(507, 27)\n",
      "[ 2018-04-25 20:04:28,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:04:29,054][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:04:29,868][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:04:30,759][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-25 20:04:31,546][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=97.46%\n",
      "[ 2018-04-25 20:04:32,340][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-25 20:04:33,167][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=98.31%\n",
      "[ 2018-04-25 20:04:33,976][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-04-25 20:04:34,739][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=98.31%\n",
      "[ 2018-04-25 20:04:35,544][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:04:35,711][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=98.48%\n",
      "[ 2018-04-25 20:04:35,715][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-25 20:04:36,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:04:37,197][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=97.46%\n",
      "[ 2018-04-25 20:04:38,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:04:38,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=99.15%\n",
      "[ 2018-04-25 20:04:39,611][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=98.31%\n",
      "[ 2018-04-25 20:04:40,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=98.31%\n",
      "[ 2018-04-25 20:04:41,296][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=97.46%\n",
      "[ 2018-04-25 20:04:42,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=99.15%\n",
      "[ 2018-04-25 20:04:42,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=99.15%\n",
      "[ 2018-04-25 20:04:43,847][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:04:43,997][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=98.39%\n",
      "[ 2018-04-25 20:04:43,999][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=97.83%\n",
      "[ 2018-04-25 20:04:44,066][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=98.32%\n",
      "[ 2018-04-25 20:04:44,129][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.31%\n",
      "[ 2018-04-25 20:04:44,173][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-04-25 20:04:44,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=98.31%\n",
      "[ 2018-04-25 20:04:44,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=99.15%\n",
      "[ 2018-04-25 20:04:44,315][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=99.15%\n",
      "[ 2018-04-25 20:04:44,351][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=97.46%\n",
      "[ 2018-04-25 20:04:44,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=97.46%\n",
      "[ 2018-04-25 20:04:44,418][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=96.61%\n",
      "[ 2018-04-25 20:04:44,450][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=98.31%\n",
      "[ 2018-04-25 20:04:44,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=98.14%\n",
      "[ 2018-04-25 20:04:44,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=97.63%\n",
      "[ 2018-04-25 20:04:44,455][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=98.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:04:44,457][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=97.83%\n",
      "[ 2018-04-25 20:04:44,459][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=98.65%, accuracy_test=97.63%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:04:44,486][cascade_classifier.transform] X_groups_test.shape=[(507, 21)]\n",
      "[ 2018-04-25 20:04:44,488][cascade_classifier.transform] group_dims=[21]\n",
      "[ 2018-04-25 20:04:44,490][cascade_classifier.transform] X_test.shape=(507, 21)\n",
      "[ 2018-04-25 20:04:44,492][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(507, 21)\n",
      "[ 2018-04-25 20:04:47,400][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(507, 27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 97.633136 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 96.646943 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.435897 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.633136 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.238659 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 93.293886 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.6422 - acc: 0.9831     \n",
      "Epoch 2/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.2232 - acc: 0.9831     \n",
      "Epoch 3/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0890 - acc: 0.9831     \n",
      "Epoch 4/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0881 - acc: 0.9831     \n",
      "Epoch 5/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0874 - acc: 0.9831     \n",
      "Epoch 6/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0870 - acc: 0.9831     \n",
      "Epoch 7/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0864 - acc: 0.9831     \n",
      "Epoch 8/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0865 - acc: 0.9831     \n",
      "Epoch 9/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0855 - acc: 0.9831     \n",
      "Epoch 10/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0849 - acc: 0.9831     \n",
      "Epoch 11/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0845 - acc: 0.9831     \n",
      "Epoch 12/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0850 - acc: 0.9831     \n",
      "Epoch 13/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0841 - acc: 0.9831     \n",
      "Epoch 14/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0832 - acc: 0.9831     \n",
      "Epoch 15/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0824 - acc: 0.9831     \n",
      "Epoch 16/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0816 - acc: 0.9831     \n",
      "Epoch 17/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0816 - acc: 0.9831     \n",
      "Epoch 18/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0802 - acc: 0.9831     \n",
      "Epoch 19/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0801 - acc: 0.9831     \n",
      "Epoch 20/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0802 - acc: 0.9831     \n",
      "Epoch 21/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0786 - acc: 0.9831     \n",
      "Epoch 22/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0781 - acc: 0.9831     \n",
      "Epoch 23/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0780 - acc: 0.9831     \n",
      "Epoch 24/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0766 - acc: 0.9831     \n",
      "Epoch 25/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0769 - acc: 0.9831     \n",
      "Epoch 26/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0748 - acc: 0.9831     \n",
      "Epoch 27/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0733 - acc: 0.9831     \n",
      "Epoch 28/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0724 - acc: 0.9831     \n",
      "Epoch 29/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0721 - acc: 0.9831     \n",
      "Epoch 30/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0707 - acc: 0.9831     \n",
      "Epoch 31/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0698 - acc: 0.9831     \n",
      "Epoch 32/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0684 - acc: 0.9831     \n",
      "Epoch 33/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0677 - acc: 0.9831     \n",
      "Epoch 34/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0668 - acc: 0.9831     \n",
      "Epoch 35/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0656 - acc: 0.9831     \n",
      "Epoch 36/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0648 - acc: 0.9831     \n",
      "Epoch 37/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0637 - acc: 0.9831     \n",
      "Epoch 38/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0622 - acc: 0.9831     \n",
      "Epoch 39/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0627 - acc: 0.9831     \n",
      "Epoch 40/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0622 - acc: 0.9831     \n",
      "Epoch 41/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0607 - acc: 0.9831     \n",
      "Epoch 42/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0615 - acc: 0.9831     \n",
      "Epoch 43/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0611 - acc: 0.9831     \n",
      "Epoch 44/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0591 - acc: 0.9831     \n",
      "Epoch 45/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0588 - acc: 0.9831     \n",
      "Epoch 46/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0584 - acc: 0.9831     \n",
      "Epoch 47/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0583 - acc: 0.9831     \n",
      "Epoch 48/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0586 - acc: 0.9831     \n",
      "Epoch 49/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0598 - acc: 0.9831     \n",
      "Epoch 50/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0570 - acc: 0.9831     \n",
      "Epoch 51/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0580 - acc: 0.9831     \n",
      "Epoch 52/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0565 - acc: 0.9831     \n",
      "Epoch 53/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0560 - acc: 0.9831     \n",
      "Epoch 54/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0563 - acc: 0.9831     \n",
      "Epoch 55/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0552 - acc: 0.9831     \n",
      "Epoch 56/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0578 - acc: 0.9831     \n",
      "Epoch 57/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0568 - acc: 0.9831     \n",
      "Epoch 58/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0550 - acc: 0.9831     \n",
      "Epoch 59/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0552 - acc: 0.9831     \n",
      "Epoch 60/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0549 - acc: 0.9831     \n",
      "Epoch 61/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0578 - acc: 0.9831     \n",
      "Epoch 62/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0540 - acc: 0.9831     \n",
      "Epoch 63/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0540 - acc: 0.9831     \n",
      "Epoch 64/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0531 - acc: 0.9831     \n",
      "Epoch 65/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0543 - acc: 0.9831     \n",
      "Epoch 66/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0541 - acc: 0.9831     \n",
      "Epoch 67/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0542 - acc: 0.9831     \n",
      "Epoch 68/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0537 - acc: 0.9831     \n",
      "Epoch 69/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0540 - acc: 0.9831     \n",
      "Epoch 70/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0530 - acc: 0.9831     \n",
      "Epoch 71/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0513 - acc: 0.9831     \n",
      "Epoch 72/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0509 - acc: 0.9831     \n",
      "Epoch 73/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0511 - acc: 0.9831     \n",
      "Epoch 74/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0517 - acc: 0.9831     \n",
      "Epoch 75/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0501 - acc: 0.9831     \n",
      "Epoch 76/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0504 - acc: 0.9831     \n",
      "Epoch 77/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0506 - acc: 0.9831     \n",
      "Epoch 78/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0482 - acc: 0.9831     \n",
      "Epoch 79/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0497 - acc: 0.9831     \n",
      "Epoch 80/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0478 - acc: 0.9831     \n",
      "Epoch 81/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0478 - acc: 0.9831     \n",
      "Epoch 82/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0477 - acc: 0.9831     \n",
      "Epoch 83/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0471 - acc: 0.9831     \n",
      "Epoch 84/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0497 - acc: 0.9831     \n",
      "Epoch 85/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0473 - acc: 0.9896     \n",
      "Epoch 86/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0469 - acc: 0.9906     \n",
      "Epoch 87/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0464 - acc: 0.9915     \n",
      "Epoch 88/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0474 - acc: 0.9906     \n",
      "Epoch 89/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0479 - acc: 0.9887     \n",
      "Epoch 90/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0480 - acc: 0.9896     \n",
      "Epoch 91/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0466 - acc: 0.9906     \n",
      "Epoch 92/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0471 - acc: 0.9906     \n",
      "Epoch 93/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0462 - acc: 0.9915     \n",
      "Epoch 94/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0467 - acc: 0.9906     \n",
      "Epoch 95/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0508 - acc: 0.9887     \n",
      "Epoch 96/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0469 - acc: 0.9906     \n",
      "Epoch 97/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0463 - acc: 0.9906     \n",
      "Epoch 98/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0468 - acc: 0.9915     \n",
      "Epoch 99/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0468 - acc: 0.9906     \n",
      "Epoch 100/100\n",
      "1062/1062 [==============================] - 0s - loss: 0.0458 - acc: 0.9915     \n",
      " 32/119 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6681 - acc: 0.9831     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3630 - acc: 0.9831     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0923 - acc: 0.9831     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0889 - acc: 0.9831     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0872 - acc: 0.9831     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0871 - acc: 0.9831     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0874 - acc: 0.9831     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0868 - acc: 0.9831     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0865 - acc: 0.9831     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0856 - acc: 0.9831     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0858 - acc: 0.9831     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0866 - acc: 0.9831     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0854 - acc: 0.9831     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0857 - acc: 0.9831     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0864 - acc: 0.9831     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0846 - acc: 0.9831     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0844 - acc: 0.9831     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0838 - acc: 0.9831     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0842 - acc: 0.9831     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0833 - acc: 0.9831     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0833 - acc: 0.9831     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0836 - acc: 0.9831     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0822 - acc: 0.9831     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0822 - acc: 0.9831     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0822 - acc: 0.9831     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0819 - acc: 0.9831     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0816 - acc: 0.9831     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0807 - acc: 0.9831     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0805 - acc: 0.9831     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0801 - acc: 0.9831     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0803 - acc: 0.9831     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0803 - acc: 0.9831     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0790 - acc: 0.9831     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0799 - acc: 0.9831     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0792 - acc: 0.9831     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0782 - acc: 0.9831     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0776 - acc: 0.9831     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0774 - acc: 0.9831     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0769 - acc: 0.9831     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0758 - acc: 0.9831     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0755 - acc: 0.9831     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0753 - acc: 0.9831     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0746 - acc: 0.9831     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0739 - acc: 0.9831     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0737 - acc: 0.9831     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0731 - acc: 0.9831     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0722 - acc: 0.9831     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0718 - acc: 0.9831     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0712 - acc: 0.9831     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0718 - acc: 0.9831     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0699 - acc: 0.9831     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0690 - acc: 0.9831     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0691 - acc: 0.9831     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0687 - acc: 0.9831     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0693 - acc: 0.9831     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0682 - acc: 0.9831     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0681 - acc: 0.9831     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0683 - acc: 0.9831     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0682 - acc: 0.9831     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0674 - acc: 0.9831     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0666 - acc: 0.9831     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0666 - acc: 0.9831     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0664 - acc: 0.9831     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0671 - acc: 0.9831     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0670 - acc: 0.9831     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0660 - acc: 0.9831     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0651 - acc: 0.9831     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0667 - acc: 0.9831     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0656 - acc: 0.9831     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0659 - acc: 0.9831     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0647 - acc: 0.9831     \n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s - loss: 0.0652 - acc: 0.9831     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0672 - acc: 0.9831     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0698 - acc: 0.9831     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0650 - acc: 0.9831     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0644 - acc: 0.9831     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0651 - acc: 0.9831     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0652 - acc: 0.9831     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0645 - acc: 0.9831     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0644 - acc: 0.9831     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0639 - acc: 0.9831     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9831     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0642 - acc: 0.9831     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0638 - acc: 0.9831     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0653 - acc: 0.9831     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0637 - acc: 0.9831     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0637 - acc: 0.9831     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0630 - acc: 0.9831     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0622 - acc: 0.9831     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0631 - acc: 0.9831     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0619 - acc: 0.9831     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0613 - acc: 0.9831     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0607 - acc: 0.9831     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0605 - acc: 0.9831     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0606 - acc: 0.9831     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0599 - acc: 0.9831     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0595 - acc: 0.9831     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0601 - acc: 0.9831     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0611 - acc: 0.9831     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0599 - acc: 0.9831     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6525 - acc: 0.9812     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2688 - acc: 0.9821     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0917 - acc: 0.9821     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0921 - acc: 0.9821     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0910 - acc: 0.9821     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0909 - acc: 0.9821     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0925 - acc: 0.9821     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0902 - acc: 0.9821     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0898 - acc: 0.9821     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0902 - acc: 0.9821     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0895 - acc: 0.9821     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0895 - acc: 0.9821     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0880 - acc: 0.9821     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0875 - acc: 0.9821     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0872 - acc: 0.9821     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0868 - acc: 0.9821     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0865 - acc: 0.9821     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0862 - acc: 0.9821     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0868 - acc: 0.9821     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0850 - acc: 0.9821     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0849 - acc: 0.9821     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0838 - acc: 0.9821     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0840 - acc: 0.9821     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0841 - acc: 0.9821     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0826 - acc: 0.9821     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0823 - acc: 0.9821     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0814 - acc: 0.9821     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0818 - acc: 0.9821     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0798 - acc: 0.9821     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0806 - acc: 0.9821     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0790 - acc: 0.9821     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0778 - acc: 0.9821     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0769 - acc: 0.9821     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0765 - acc: 0.9821     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0761 - acc: 0.9821     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0742 - acc: 0.9821     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0739 - acc: 0.9821     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0729 - acc: 0.9821     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0734 - acc: 0.9821     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0726 - acc: 0.9821     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0711 - acc: 0.9821     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0716 - acc: 0.9821     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0699 - acc: 0.9821     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0698 - acc: 0.9821     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0690 - acc: 0.9821     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0698 - acc: 0.9821     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0682 - acc: 0.9821     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0687 - acc: 0.9821     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0675 - acc: 0.9821     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0674 - acc: 0.9821     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0667 - acc: 0.9821     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0662 - acc: 0.9821     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0668 - acc: 0.9821     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0667 - acc: 0.9821     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0659 - acc: 0.9821     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0667 - acc: 0.9821     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0656 - acc: 0.9821     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0654 - acc: 0.9821     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0645 - acc: 0.9821     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0647 - acc: 0.9821     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0648 - acc: 0.9821     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9821     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0641 - acc: 0.9821     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0657 - acc: 0.9821     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0659 - acc: 0.9821     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0646 - acc: 0.9840     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0633 - acc: 0.9859     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0633 - acc: 0.9859     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0629 - acc: 0.9859     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0630 - acc: 0.9859     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0616 - acc: 0.9849     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0617 - acc: 0.9859     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0604 - acc: 0.9849     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0606 - acc: 0.9859     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0596 - acc: 0.9859     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0599 - acc: 0.9859     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0568 - acc: 0.9878     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0568 - acc: 0.9878     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0577 - acc: 0.9868     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0553 - acc: 0.9878     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0605 - acc: 0.9859     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0669 - acc: 0.9831     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0582 - acc: 0.9868     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0579 - acc: 0.9868     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0540 - acc: 0.9897     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0532 - acc: 0.9878     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0536 - acc: 0.9887     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0534 - acc: 0.9897     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0526 - acc: 0.9897     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0521 - acc: 0.9906     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0518 - acc: 0.9897     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0511 - acc: 0.9897     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0517 - acc: 0.9887     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0526 - acc: 0.9906     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0508 - acc: 0.9906     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0498 - acc: 0.9906     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0503 - acc: 0.9906     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0496 - acc: 0.9906     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0500 - acc: 0.9906     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0498 - acc: 0.9906     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6589 - acc: 0.9831     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2758 - acc: 0.9831     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0916 - acc: 0.9831     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0886 - acc: 0.9831     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0879 - acc: 0.9831     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0873 - acc: 0.9831     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0874 - acc: 0.9831     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0868 - acc: 0.9831     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0865 - acc: 0.9831     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0860 - acc: 0.9831     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0855 - acc: 0.9831     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0849 - acc: 0.9831     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0853 - acc: 0.9831     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0838 - acc: 0.9831     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0847 - acc: 0.9831     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0845 - acc: 0.9831     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0829 - acc: 0.9831     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0823 - acc: 0.9831     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0830 - acc: 0.9831     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0817 - acc: 0.9831     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0822 - acc: 0.9831     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0809 - acc: 0.9831     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0814 - acc: 0.9831     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0800 - acc: 0.9831     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0799 - acc: 0.9831     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0789 - acc: 0.9831     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0784 - acc: 0.9831     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0773 - acc: 0.9831     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0769 - acc: 0.9831     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0766 - acc: 0.9831     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0756 - acc: 0.9831     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0753 - acc: 0.9831     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0745 - acc: 0.9831     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0739 - acc: 0.9831     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0736 - acc: 0.9831     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0723 - acc: 0.9831     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0718 - acc: 0.9831     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0713 - acc: 0.9831     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0700 - acc: 0.9831     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0693 - acc: 0.9831     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0685 - acc: 0.9831     \n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s - loss: 0.0686 - acc: 0.9831     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0676 - acc: 0.9831     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0670 - acc: 0.9831     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0683 - acc: 0.9831     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0668 - acc: 0.9831     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0662 - acc: 0.9831     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0654 - acc: 0.9831     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0655 - acc: 0.9831     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0648 - acc: 0.9831     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0641 - acc: 0.9831     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9831     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0638 - acc: 0.9831     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0639 - acc: 0.9831     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9831     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0628 - acc: 0.9831     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0644 - acc: 0.9831     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0650 - acc: 0.9831     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0624 - acc: 0.9831     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0633 - acc: 0.9831     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0623 - acc: 0.9831     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0621 - acc: 0.9831     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0630 - acc: 0.9831     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0613 - acc: 0.9831     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0621 - acc: 0.9831     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0625 - acc: 0.9831     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0617 - acc: 0.9831     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0623 - acc: 0.9831     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0614 - acc: 0.9831     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0606 - acc: 0.9831     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0632 - acc: 0.9831     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0601 - acc: 0.9831     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0616 - acc: 0.9831     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0611 - acc: 0.9831     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0607 - acc: 0.9831     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0608 - acc: 0.9831     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0603 - acc: 0.9831     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0591 - acc: 0.9831     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0596 - acc: 0.9831     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0599 - acc: 0.9831     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0615 - acc: 0.9831     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0601 - acc: 0.9831     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0595 - acc: 0.9831     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0581 - acc: 0.9831     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0584 - acc: 0.9831     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0578 - acc: 0.9831     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0574 - acc: 0.9831     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0573 - acc: 0.9831     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0561 - acc: 0.9831     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0558 - acc: 0.9831     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0562 - acc: 0.9831     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0556 - acc: 0.9831     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0552 - acc: 0.9831     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0559 - acc: 0.9831     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0538 - acc: 0.9831     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0540 - acc: 0.9831     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0561 - acc: 0.9831     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0538 - acc: 0.9831     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0556 - acc: 0.9831     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0543 - acc: 0.9831     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6828 - acc: 0.9548     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4680 - acc: 0.9831     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0978 - acc: 0.9831     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0880 - acc: 0.9831     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0876 - acc: 0.9831     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0871 - acc: 0.9831     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0880 - acc: 0.9831     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0862 - acc: 0.9831     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0853 - acc: 0.9831     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0848 - acc: 0.9831     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0858 - acc: 0.9831     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0836 - acc: 0.9831     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0840 - acc: 0.9831     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0822 - acc: 0.9831     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0818 - acc: 0.9831     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0812 - acc: 0.9831     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0821 - acc: 0.9831     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0811 - acc: 0.9831     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0790 - acc: 0.9831     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0785 - acc: 0.9831     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0774 - acc: 0.9831     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0794 - acc: 0.9831     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0792 - acc: 0.9831     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0762 - acc: 0.9831     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0756 - acc: 0.9831     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0747 - acc: 0.9831     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0749 - acc: 0.9831     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0727 - acc: 0.9831     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0725 - acc: 0.9831     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0727 - acc: 0.9831     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0717 - acc: 0.9831     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0706 - acc: 0.9831     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0708 - acc: 0.9831     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0691 - acc: 0.9831     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0686 - acc: 0.9831     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0681 - acc: 0.9831     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0674 - acc: 0.9831     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0681 - acc: 0.9831     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0681 - acc: 0.9831     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0699 - acc: 0.9831     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0664 - acc: 0.9831     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0658 - acc: 0.9831     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0665 - acc: 0.9831     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0653 - acc: 0.9831     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0684 - acc: 0.9831     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0650 - acc: 0.9831     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0666 - acc: 0.9831     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0657 - acc: 0.9831     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0647 - acc: 0.9831     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0651 - acc: 0.9831     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0647 - acc: 0.9831     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0649 - acc: 0.9831     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9831     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0639 - acc: 0.9831     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0631 - acc: 0.9831     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0629 - acc: 0.9831     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0629 - acc: 0.9831     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0635 - acc: 0.9831     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0628 - acc: 0.9831     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0629 - acc: 0.9831     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0632 - acc: 0.9831     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0627 - acc: 0.9831     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0628 - acc: 0.9831     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0636 - acc: 0.9831     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0621 - acc: 0.9831     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0612 - acc: 0.9831     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0615 - acc: 0.9831     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0620 - acc: 0.9831     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0622 - acc: 0.9831     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0622 - acc: 0.9831     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0627 - acc: 0.9831     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0612 - acc: 0.9831     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0610 - acc: 0.9831     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0638 - acc: 0.9831     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0630 - acc: 0.9831     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0631 - acc: 0.9831     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0608 - acc: 0.9831     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0605 - acc: 0.9831     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0610 - acc: 0.9831     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0605 - acc: 0.9831     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0619 - acc: 0.9831     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0617 - acc: 0.9831     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0612 - acc: 0.9831     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0602 - acc: 0.9831     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0605 - acc: 0.9831     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0599 - acc: 0.9831     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0601 - acc: 0.9831     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0600 - acc: 0.9831     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0607 - acc: 0.9831     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0595 - acc: 0.9831     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0603 - acc: 0.9831     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0604 - acc: 0.9831     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0598 - acc: 0.9831     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0608 - acc: 0.9831     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0596 - acc: 0.9831     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0597 - acc: 0.9831     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0603 - acc: 0.9831     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0597 - acc: 0.9831     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0596 - acc: 0.9831     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0601 - acc: 0.9831     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6441 - acc: 0.9831     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2546 - acc: 0.9831     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0849 - acc: 0.9831     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0873 - acc: 0.9831     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0865 - acc: 0.9831     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0859 - acc: 0.9831     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0855 - acc: 0.9831     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0849 - acc: 0.9831     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0841 - acc: 0.9831     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0835 - acc: 0.9831     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0829 - acc: 0.9831     \n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s - loss: 0.0824 - acc: 0.9831     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0816 - acc: 0.9831     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0805 - acc: 0.9831     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0807 - acc: 0.9831     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0802 - acc: 0.9831     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0798 - acc: 0.9831     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0780 - acc: 0.9831     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0770 - acc: 0.9831     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0764 - acc: 0.9831     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0769 - acc: 0.9831     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0763 - acc: 0.9831     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0744 - acc: 0.9831     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0725 - acc: 0.9831     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0727 - acc: 0.9831     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0711 - acc: 0.9831     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0700 - acc: 0.9831     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0700 - acc: 0.9831     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0770 - acc: 0.9831     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0683 - acc: 0.9831     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0685 - acc: 0.9831     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0702 - acc: 0.9831     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0665 - acc: 0.9831     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0661 - acc: 0.9831     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0662 - acc: 0.9831     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0680 - acc: 0.9831     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0671 - acc: 0.9831     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0662 - acc: 0.9831     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0654 - acc: 0.9831     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0652 - acc: 0.9831     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0650 - acc: 0.9831     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0658 - acc: 0.9831     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9859     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0671 - acc: 0.9849     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0651 - acc: 0.9868     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0655 - acc: 0.9868     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0631 - acc: 0.9868     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0653 - acc: 0.9859     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9859     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0632 - acc: 0.9849     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0646 - acc: 0.9859     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0669 - acc: 0.9849     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0636 - acc: 0.9859     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0628 - acc: 0.9868     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9859     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0630 - acc: 0.9859     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0620 - acc: 0.9868     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0615 - acc: 0.9868     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0618 - acc: 0.9859     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0618 - acc: 0.9868     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0620 - acc: 0.9868     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0610 - acc: 0.9859     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0607 - acc: 0.9868     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0606 - acc: 0.9868     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0619 - acc: 0.9868     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0609 - acc: 0.9868     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0605 - acc: 0.9868     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0594 - acc: 0.9878     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0592 - acc: 0.9878     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0594 - acc: 0.9878     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0589 - acc: 0.9868     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0591 - acc: 0.9868     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0587 - acc: 0.9878     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0589 - acc: 0.9878     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0599 - acc: 0.9868     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0649 - acc: 0.9849     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0698 - acc: 0.9849     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0607 - acc: 0.9859     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0598 - acc: 0.9868     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0565 - acc: 0.9868     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0569 - acc: 0.9868     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0609 - acc: 0.9859     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0579 - acc: 0.9878     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0558 - acc: 0.9887     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0558 - acc: 0.9897     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0547 - acc: 0.9897     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0547 - acc: 0.9897     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0534 - acc: 0.9906     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0538 - acc: 0.9887     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0554 - acc: 0.9878     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0531 - acc: 0.9906     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0537 - acc: 0.9897     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0533 - acc: 0.9906     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0528 - acc: 0.9906     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0531 - acc: 0.9906     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0536 - acc: 0.9897     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0545 - acc: 0.9906     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0518 - acc: 0.9906     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0551 - acc: 0.9878     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0527 - acc: 0.9906     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6854 - acc: 0.9238          \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5848 - acc: 0.9840     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1258 - acc: 0.9840     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0861 - acc: 0.9840     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0840 - acc: 0.9840     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0836 - acc: 0.9840     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0831 - acc: 0.9840     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0833 - acc: 0.9840     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0829 - acc: 0.9840     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0825 - acc: 0.9840     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0826 - acc: 0.9840     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0817 - acc: 0.9840     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0811 - acc: 0.9840     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0814 - acc: 0.9840     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0804 - acc: 0.9840     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0805 - acc: 0.9840     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0798 - acc: 0.9840     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0795 - acc: 0.9840     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0790 - acc: 0.9840     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0779 - acc: 0.9840     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0776 - acc: 0.9840     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0767 - acc: 0.9840     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0766 - acc: 0.9840     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0765 - acc: 0.9840     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0745 - acc: 0.9840     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0744 - acc: 0.9840     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0744 - acc: 0.9840     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0744 - acc: 0.9840     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0770 - acc: 0.9840     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0719 - acc: 0.9840     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0737 - acc: 0.9840     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0709 - acc: 0.9840     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0710 - acc: 0.9840     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0695 - acc: 0.9840     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0679 - acc: 0.9840     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0669 - acc: 0.9840     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0664 - acc: 0.9840     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0666 - acc: 0.9840     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0662 - acc: 0.9840     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0653 - acc: 0.9840     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0651 - acc: 0.9840     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0662 - acc: 0.9840     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0652 - acc: 0.9840     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0666 - acc: 0.9840     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0655 - acc: 0.9840     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0640 - acc: 0.9840     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0630 - acc: 0.9840     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0628 - acc: 0.9840     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0643 - acc: 0.9840     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0639 - acc: 0.9840     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0634 - acc: 0.9840     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0637 - acc: 0.9840     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0619 - acc: 0.9840     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0618 - acc: 0.9840     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0616 - acc: 0.9840     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0634 - acc: 0.9840     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0619 - acc: 0.9840     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0629 - acc: 0.9840     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0628 - acc: 0.9840     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0615 - acc: 0.9840     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0605 - acc: 0.9840     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0601 - acc: 0.9840     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0612 - acc: 0.9840     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0642 - acc: 0.9840     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0624 - acc: 0.9840     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0622 - acc: 0.9840     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0600 - acc: 0.9840     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0628 - acc: 0.9840     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0598 - acc: 0.9840     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0601 - acc: 0.9840     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0593 - acc: 0.9840     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0613 - acc: 0.9840     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0591 - acc: 0.9840     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0596 - acc: 0.9840     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0594 - acc: 0.9840     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0589 - acc: 0.9840     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0586 - acc: 0.9840     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0595 - acc: 0.9840     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0596 - acc: 0.9840     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0603 - acc: 0.9840     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0591 - acc: 0.9840     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0586 - acc: 0.9840     \n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s - loss: 0.0579 - acc: 0.9840     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0580 - acc: 0.9840     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0581 - acc: 0.9840     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0588 - acc: 0.9840     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0587 - acc: 0.9840     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0572 - acc: 0.9840     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0572 - acc: 0.9840     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0573 - acc: 0.9840     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0588 - acc: 0.9840     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0591 - acc: 0.9840     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0587 - acc: 0.9840     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0577 - acc: 0.9840     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0571 - acc: 0.9840     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0573 - acc: 0.9840     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0567 - acc: 0.9840     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0565 - acc: 0.9840     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0565 - acc: 0.9840     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0558 - acc: 0.9840     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6856 - acc: 0.9247     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6694 - acc: 0.9812     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6538 - acc: 0.9812     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6386 - acc: 0.9812     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6239 - acc: 0.9812     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6095 - acc: 0.9812     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5955 - acc: 0.9812     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5821 - acc: 0.9812     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5689 - acc: 0.9812     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5560 - acc: 0.9812     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5435 - acc: 0.9812     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5314 - acc: 0.9812     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5195 - acc: 0.9812     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.5081 - acc: 0.9812     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4971 - acc: 0.9812     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4862 - acc: 0.9812     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4757 - acc: 0.9812     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4654 - acc: 0.9812     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4554 - acc: 0.9812     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4459 - acc: 0.9812     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4365 - acc: 0.9812     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4274 - acc: 0.9812     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4185 - acc: 0.9812     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4099 - acc: 0.9812     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.4015 - acc: 0.9812     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3933 - acc: 0.9812     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3854 - acc: 0.9812     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3777 - acc: 0.9812     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3702 - acc: 0.9812     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3629 - acc: 0.9812     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3559 - acc: 0.9812     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3491 - acc: 0.9812     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3424 - acc: 0.9812     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3359 - acc: 0.9812     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3296 - acc: 0.9812     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3234 - acc: 0.9812     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3175 - acc: 0.9812     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3116 - acc: 0.9812     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3060 - acc: 0.9812     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3005 - acc: 0.9812     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2952 - acc: 0.9812     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2901 - acc: 0.9812     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2850 - acc: 0.9812     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2801 - acc: 0.9812     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2753 - acc: 0.9812     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2707 - acc: 0.9812     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2662 - acc: 0.9812     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2617 - acc: 0.9812     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2575 - acc: 0.9812     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2533 - acc: 0.9812     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2492 - acc: 0.9812     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2453 - acc: 0.9812     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2415 - acc: 0.9812     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2377 - acc: 0.9812     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2341 - acc: 0.9812     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2305 - acc: 0.9812     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2271 - acc: 0.9812     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2237 - acc: 0.9812     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2204 - acc: 0.9812     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2172 - acc: 0.9812     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2141 - acc: 0.9812     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2111 - acc: 0.9812     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2082 - acc: 0.9812     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2054 - acc: 0.9812     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2026 - acc: 0.9812     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1999 - acc: 0.9812     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1972 - acc: 0.9812     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1946 - acc: 0.9812     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1921 - acc: 0.9812     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1896 - acc: 0.9812     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1872 - acc: 0.9812     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1849 - acc: 0.9812     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1826 - acc: 0.9812     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1804 - acc: 0.9812     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1782 - acc: 0.9812     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1761 - acc: 0.9812     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1740 - acc: 0.9812     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1720 - acc: 0.9812     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1701 - acc: 0.9812     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1682 - acc: 0.9812     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1663 - acc: 0.9812     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1645 - acc: 0.9812     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1627 - acc: 0.9812     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1610 - acc: 0.9812     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1593 - acc: 0.9812     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1576 - acc: 0.9812     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1560 - acc: 0.9812     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1544 - acc: 0.9812     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1529 - acc: 0.9812     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1514 - acc: 0.9812     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1500 - acc: 0.9812     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1485 - acc: 0.9812     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1471 - acc: 0.9812     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1458 - acc: 0.9812     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1445 - acc: 0.9812     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1432 - acc: 0.9812     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1419 - acc: 0.9812     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1407 - acc: 0.9812     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1395 - acc: 0.9812     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.1383 - acc: 0.9812     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6667 - acc: 0.9859     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.3880 - acc: 0.9859     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0885 - acc: 0.9859     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0757 - acc: 0.9859     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0762 - acc: 0.9859     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0756 - acc: 0.9859     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0751 - acc: 0.9859     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0750 - acc: 0.9859     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0741 - acc: 0.9859     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0744 - acc: 0.9859     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0736 - acc: 0.9859     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0738 - acc: 0.9859     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0736 - acc: 0.9859     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0732 - acc: 0.9859     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0725 - acc: 0.9859     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0723 - acc: 0.9859     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0721 - acc: 0.9859     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0717 - acc: 0.9859     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0720 - acc: 0.9859     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0713 - acc: 0.9859     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0710 - acc: 0.9859     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0706 - acc: 0.9859     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0707 - acc: 0.9859     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0702 - acc: 0.9859     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0696 - acc: 0.9859     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0695 - acc: 0.9859     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0687 - acc: 0.9859     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0685 - acc: 0.9859     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0683 - acc: 0.9859     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0678 - acc: 0.9859     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0670 - acc: 0.9859     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0675 - acc: 0.9859     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0665 - acc: 0.9859     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0671 - acc: 0.9859     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0668 - acc: 0.9859     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0655 - acc: 0.9859     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0645 - acc: 0.9859     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0641 - acc: 0.9859     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0639 - acc: 0.9859     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0643 - acc: 0.9859     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0623 - acc: 0.9859     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0618 - acc: 0.9859     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0615 - acc: 0.9859     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0613 - acc: 0.9859     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0599 - acc: 0.9859     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0595 - acc: 0.9859     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0594 - acc: 0.9859     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0581 - acc: 0.9859     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0578 - acc: 0.9859     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0573 - acc: 0.9859     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0570 - acc: 0.9859     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0581 - acc: 0.9859     \n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 0s - loss: 0.0569 - acc: 0.9859     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0555 - acc: 0.9859     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0555 - acc: 0.9859     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0541 - acc: 0.9859     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0550 - acc: 0.9859     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0549 - acc: 0.9859     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0550 - acc: 0.9859     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0533 - acc: 0.9859     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0527 - acc: 0.9859     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0536 - acc: 0.9859     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0525 - acc: 0.9859     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0523 - acc: 0.9859     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0520 - acc: 0.9859     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0521 - acc: 0.9859     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0517 - acc: 0.9859     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0542 - acc: 0.9859     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0526 - acc: 0.9859     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0510 - acc: 0.9859     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0514 - acc: 0.9859     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0512 - acc: 0.9859     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0503 - acc: 0.9859     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0498 - acc: 0.9859     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0505 - acc: 0.9859     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0498 - acc: 0.9859     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0554 - acc: 0.9859     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0498 - acc: 0.9859     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0504 - acc: 0.9859     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0489 - acc: 0.9859     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0489 - acc: 0.9859     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0487 - acc: 0.9859     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0506 - acc: 0.9859     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0483 - acc: 0.9859     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0480 - acc: 0.9859     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0479 - acc: 0.9859     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0475 - acc: 0.9859     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0476 - acc: 0.9859     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0465 - acc: 0.9859     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0467 - acc: 0.9859     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0473 - acc: 0.9859     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0463 - acc: 0.9859     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0465 - acc: 0.9859     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0461 - acc: 0.9859     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0459 - acc: 0.9859     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0454 - acc: 0.9859     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0457 - acc: 0.9859     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0448 - acc: 0.9859     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0448 - acc: 0.9859     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0458 - acc: 0.9859     \n",
      " 32/118 [=======>......................] - ETA: 0sEpoch 1/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6852 - acc: 0.8956     \n",
      "Epoch 2/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.6103 - acc: 0.9821     \n",
      "Epoch 3/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.2302 - acc: 0.9821     \n",
      "Epoch 4/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0919 - acc: 0.9821     \n",
      "Epoch 5/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0923 - acc: 0.9821     \n",
      "Epoch 6/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0920 - acc: 0.9821     \n",
      "Epoch 7/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0918 - acc: 0.9821     \n",
      "Epoch 8/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0908 - acc: 0.9821     \n",
      "Epoch 9/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0910 - acc: 0.9821     \n",
      "Epoch 10/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0910 - acc: 0.9821     \n",
      "Epoch 11/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0904 - acc: 0.9821     \n",
      "Epoch 12/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0899 - acc: 0.9821     \n",
      "Epoch 13/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0896 - acc: 0.9821     \n",
      "Epoch 14/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0896 - acc: 0.9821     \n",
      "Epoch 15/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0887 - acc: 0.9821     \n",
      "Epoch 16/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0889 - acc: 0.9821     \n",
      "Epoch 17/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0886 - acc: 0.9821     \n",
      "Epoch 18/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0878 - acc: 0.9821     \n",
      "Epoch 19/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0880 - acc: 0.9821     \n",
      "Epoch 20/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0877 - acc: 0.9821     \n",
      "Epoch 21/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0873 - acc: 0.9821     \n",
      "Epoch 22/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0867 - acc: 0.9821     \n",
      "Epoch 23/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0868 - acc: 0.9821     \n",
      "Epoch 24/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0868 - acc: 0.9821     \n",
      "Epoch 25/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0857 - acc: 0.9821     \n",
      "Epoch 26/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0857 - acc: 0.9821     \n",
      "Epoch 27/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0859 - acc: 0.9821     \n",
      "Epoch 28/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0854 - acc: 0.9821     \n",
      "Epoch 29/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0851 - acc: 0.9821     \n",
      "Epoch 30/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0845 - acc: 0.9821     \n",
      "Epoch 31/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0846 - acc: 0.9821     \n",
      "Epoch 32/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0839 - acc: 0.9821     \n",
      "Epoch 33/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0834 - acc: 0.9821     \n",
      "Epoch 34/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0834 - acc: 0.9821     \n",
      "Epoch 35/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0830 - acc: 0.9821     \n",
      "Epoch 36/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0828 - acc: 0.9821     \n",
      "Epoch 37/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0823 - acc: 0.9821     \n",
      "Epoch 38/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0816 - acc: 0.9821     \n",
      "Epoch 39/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0814 - acc: 0.9821     \n",
      "Epoch 40/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0811 - acc: 0.9821     \n",
      "Epoch 41/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0806 - acc: 0.9821     \n",
      "Epoch 42/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0823 - acc: 0.9821     \n",
      "Epoch 43/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0805 - acc: 0.9821     \n",
      "Epoch 44/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0795 - acc: 0.9821     \n",
      "Epoch 45/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0788 - acc: 0.9821     \n",
      "Epoch 46/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0785 - acc: 0.9821     \n",
      "Epoch 47/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0778 - acc: 0.9821     \n",
      "Epoch 48/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0777 - acc: 0.9821     \n",
      "Epoch 49/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0768 - acc: 0.9821     \n",
      "Epoch 50/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0766 - acc: 0.9821     \n",
      "Epoch 51/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0775 - acc: 0.9821     \n",
      "Epoch 52/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0760 - acc: 0.9821     \n",
      "Epoch 53/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0758 - acc: 0.9821     \n",
      "Epoch 54/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0751 - acc: 0.9821     \n",
      "Epoch 55/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0768 - acc: 0.9821     \n",
      "Epoch 56/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0748 - acc: 0.9821     \n",
      "Epoch 57/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0743 - acc: 0.9821     \n",
      "Epoch 58/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0735 - acc: 0.9821     \n",
      "Epoch 59/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0736 - acc: 0.9821     \n",
      "Epoch 60/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0729 - acc: 0.9821     \n",
      "Epoch 61/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0728 - acc: 0.9821     \n",
      "Epoch 62/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0724 - acc: 0.9821     \n",
      "Epoch 63/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0725 - acc: 0.9821     \n",
      "Epoch 64/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0721 - acc: 0.9821     \n",
      "Epoch 65/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0725 - acc: 0.9821     \n",
      "Epoch 66/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0716 - acc: 0.9821     \n",
      "Epoch 67/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0712 - acc: 0.9821     \n",
      "Epoch 68/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0712 - acc: 0.9821     \n",
      "Epoch 69/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0721 - acc: 0.9821     \n",
      "Epoch 70/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0709 - acc: 0.9821     \n",
      "Epoch 71/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0703 - acc: 0.9821     \n",
      "Epoch 72/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0705 - acc: 0.9821     \n",
      "Epoch 73/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0699 - acc: 0.9821     \n",
      "Epoch 74/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0706 - acc: 0.9821     \n",
      "Epoch 75/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0694 - acc: 0.9821     \n",
      "Epoch 76/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0699 - acc: 0.9821     \n",
      "Epoch 77/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0696 - acc: 0.9821     \n",
      "Epoch 78/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0691 - acc: 0.9821     \n",
      "Epoch 79/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0704 - acc: 0.9821     \n",
      "Epoch 80/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0699 - acc: 0.9821     \n",
      "Epoch 81/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0693 - acc: 0.9821     \n",
      "Epoch 82/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0694 - acc: 0.9821     \n",
      "Epoch 83/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0685 - acc: 0.9821     \n",
      "Epoch 84/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0684 - acc: 0.9821     \n",
      "Epoch 85/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0689 - acc: 0.9821     \n",
      "Epoch 86/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0691 - acc: 0.9821     \n",
      "Epoch 87/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0685 - acc: 0.9821     \n",
      "Epoch 88/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0680 - acc: 0.9821     \n",
      "Epoch 89/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0683 - acc: 0.9821     \n",
      "Epoch 90/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0680 - acc: 0.9821     \n",
      "Epoch 91/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0686 - acc: 0.9821     \n",
      "Epoch 92/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0668 - acc: 0.9821     \n",
      "Epoch 93/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0671 - acc: 0.9821     \n",
      "Epoch 94/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0674 - acc: 0.9821     \n",
      "Epoch 95/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0666 - acc: 0.9821     \n",
      "Epoch 96/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0659 - acc: 0.9821     \n",
      "Epoch 97/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0653 - acc: 0.9821     \n",
      "Epoch 98/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0674 - acc: 0.9821     \n",
      "Epoch 99/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0657 - acc: 0.9821     \n",
      "Epoch 100/100\n",
      "1063/1063 [==============================] - 0s - loss: 0.0644 - acc: 0.9821     \n",
      " 32/118 [=======>......................] - ETA: 0sAccuracy mean: 0.983065089837\n",
      "Accuracy variance: 0.0107196711682\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
