{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att13</th>\n",
       "      <th>att14</th>\n",
       "      <th>att15</th>\n",
       "      <th>att16</th>\n",
       "      <th>att17</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.323657</td>\n",
       "      <td>0.793785</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.660063</td>\n",
       "      <td>0.622244</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.760762</td>\n",
       "      <td>0.671655</td>\n",
       "      <td>0.603723</td>\n",
       "      <td>0.636170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281899</td>\n",
       "      <td>0.203557</td>\n",
       "      <td>0.286607</td>\n",
       "      <td>0.474383</td>\n",
       "      <td>0.352483</td>\n",
       "      <td>0.358857</td>\n",
       "      <td>0.275626</td>\n",
       "      <td>0.465937</td>\n",
       "      <td>0.220884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423803</td>\n",
       "      <td>0.769774</td>\n",
       "      <td>0.632130</td>\n",
       "      <td>0.572471</td>\n",
       "      <td>0.747495</td>\n",
       "      <td>0.670408</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.617958</td>\n",
       "      <td>0.637411</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302671</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.296429</td>\n",
       "      <td>0.383302</td>\n",
       "      <td>0.545278</td>\n",
       "      <td>0.394286</td>\n",
       "      <td>0.451025</td>\n",
       "      <td>0.470803</td>\n",
       "      <td>0.468541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.477504</td>\n",
       "      <td>0.580508</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.476538</td>\n",
       "      <td>0.851703</td>\n",
       "      <td>0.509184</td>\n",
       "      <td>0.745861</td>\n",
       "      <td>0.785211</td>\n",
       "      <td>0.508865</td>\n",
       "      <td>0.519149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.384387</td>\n",
       "      <td>0.229464</td>\n",
       "      <td>0.350095</td>\n",
       "      <td>0.117819</td>\n",
       "      <td>0.406857</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.402676</td>\n",
       "      <td>0.370817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.645864</td>\n",
       "      <td>0.570621</td>\n",
       "      <td>0.525029</td>\n",
       "      <td>0.631908</td>\n",
       "      <td>0.682365</td>\n",
       "      <td>0.382653</td>\n",
       "      <td>0.478477</td>\n",
       "      <td>0.608275</td>\n",
       "      <td>0.476950</td>\n",
       "      <td>0.190426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500495</td>\n",
       "      <td>0.555336</td>\n",
       "      <td>0.463393</td>\n",
       "      <td>0.537951</td>\n",
       "      <td>0.564752</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.576310</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.597055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219158</td>\n",
       "      <td>0.690678</td>\n",
       "      <td>0.530850</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.687375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.523050</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.408103</td>\n",
       "      <td>0.322321</td>\n",
       "      <td>0.425996</td>\n",
       "      <td>0.400195</td>\n",
       "      <td>0.701714</td>\n",
       "      <td>0.515945</td>\n",
       "      <td>0.294404</td>\n",
       "      <td>0.463186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0  0.323657  0.793785  0.848661  0.660063  0.622244  0.755102  0.760762   \n",
       "1  0.423803  0.769774  0.632130  0.572471  0.747495  0.670408  0.715232   \n",
       "2  0.477504  0.580508  0.554133  0.476538  0.851703  0.509184  0.745861   \n",
       "3  0.645864  0.570621  0.525029  0.631908  0.682365  0.382653  0.478477   \n",
       "4  0.219158  0.690678  0.530850  0.715328  0.687375  0.571429  0.649007   \n",
       "\n",
       "       att8      att9     att10   ...        att13     att14     att15  \\\n",
       "0  0.671655  0.603723  0.636170   ...     0.281899  0.203557  0.286607   \n",
       "1  0.617958  0.637411  0.457447   ...     0.302671  0.375494  0.296429   \n",
       "2  0.785211  0.508865  0.519149   ...     0.341246  0.384387  0.229464   \n",
       "3  0.608275  0.476950  0.190426   ...     0.500495  0.555336  0.463393   \n",
       "4  0.562500  0.523050  0.303191   ...     0.190900  0.408103  0.322321   \n",
       "\n",
       "      att16     att17     att18     att19     att20     att21  outlier  \n",
       "0  0.474383  0.352483  0.358857  0.275626  0.465937  0.220884        1  \n",
       "1  0.383302  0.545278  0.394286  0.451025  0.470803  0.468541        1  \n",
       "2  0.350095  0.117819  0.406857  0.149203  0.402676  0.370817        1  \n",
       "3  0.537951  0.564752  0.485714  0.576310  0.518248  0.597055        1  \n",
       "4  0.425996  0.400195  0.701714  0.515945  0.294404  0.463186        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    " \n",
    "df=pd.read_csv('Waveform_withoutdupl_norm_v01.csv')  \n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3443, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/waveform.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,21]\n",
    "X = df[:,0:21]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:34:05,481][cascade_classifier.fit_transform] X_groups_train.shape=[(2410, 21)],y_train.shape=(2410,),X_groups_test.shape=[(1033, 21)],y_test.shape=(1033,)\n",
      "[ 2018-04-25 20:34:05,483][cascade_classifier.fit_transform] group_dims=[21]\n",
      "[ 2018-04-25 20:34:05,485][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-04-25 20:34:05,486][cascade_classifier.fit_transform] group_ends=[21]\n",
      "[ 2018-04-25 20:34:05,488][cascade_classifier.fit_transform] X_train.shape=(2410, 21),X_test.shape=(1033, 21)\n",
      "[ 2018-04-25 20:34:05,489][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(2410, 21), X_cur_test.shape=(1033, 21)\n",
      "[ 2018-04-25 20:34:06,115][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=96.69%\n",
      "[ 2018-04-25 20:34:06,884][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-04-25 20:34:07,649][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-04-25 20:34:08,498][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-04-25 20:34:09,292][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=97.10%\n",
      "[ 2018-04-25 20:34:10,064][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=97.10%\n",
      "[ 2018-04-25 20:34:10,926][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:34:11,731][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=97.10%\n",
      "[ 2018-04-25 20:34:12,526][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-04-25 20:34:13,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=97.50%\n",
      "[ 2018-04-25 20:34:13,450][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=97.30%\n",
      "[ 2018-04-25 20:34:13,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.29%\n",
      "[ 2018-04-25 20:34:14,154][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-04-25 20:34:14,911][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-04-25 20:34:15,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=97.10%\n",
      "[ 2018-04-25 20:34:16,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-04-25 20:34:17,328][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-04-25 20:34:18,155][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-04-25 20:34:18,918][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:34:19,724][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-04-25 20:34:20,654][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,509][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=97.50%\n",
      "[ 2018-04-25 20:34:21,665][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=97.30%\n",
      "[ 2018-04-25 20:34:21,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.29%\n",
      "[ 2018-04-25 20:34:21,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=96.69%\n",
      "[ 2018-04-25 20:34:21,763][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,776][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,789][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,801][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,812][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,833][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=96.68%\n",
      "[ 2018-04-25 20:34:21,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=97.10%\n",
      "[ 2018-04-25 20:34:21,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=97.08%\n",
      "[ 2018-04-25 20:34:21,854][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=97.01%\n",
      "[ 2018-04-25 20:34:21,855][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.19%\n",
      "[ 2018-04-25 20:34:21,857][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=97.10%\n",
      "[ 2018-04-25 20:34:21,858][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.19%\n",
      "[ 2018-04-25 20:34:21,861][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:34:22,443][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-04-25 20:34:23,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-04-25 20:34:24,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=97.51%\n",
      "[ 2018-04-25 20:34:24,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=98.34%\n",
      "[ 2018-04-25 20:34:25,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=97.10%\n",
      "[ 2018-04-25 20:34:26,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-04-25 20:34:27,344][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=97.51%\n",
      "[ 2018-04-25 20:34:28,136][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=96.27%\n",
      "[ 2018-04-25 20:34:28,921][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:34:29,762][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=99.17%\n",
      "[ 2018-04-25 20:34:29,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=97.63%\n",
      "[ 2018-04-25 20:34:29,910][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=97.97%\n",
      "[ 2018-04-25 20:34:30,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=98.76%\n",
      "[ 2018-04-25 20:34:31,470][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=98.76%\n",
      "[ 2018-04-25 20:34:32,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:34:33,081][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=98.76%\n",
      "[ 2018-04-25 20:34:33,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:34:34,691][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=97.10%\n",
      "[ 2018-04-25 20:34:35,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:34:36,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=96.68%\n",
      "[ 2018-04-25 20:34:37,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=98.34%\n",
      "[ 2018-04-25 20:34:38,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:34:38,182][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-04-25 20:34:38,184][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:34:38,209][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-04-25 20:34:38,226][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=96.68%\n",
      "[ 2018-04-25 20:34:38,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=97.51%\n",
      "[ 2018-04-25 20:34:38,258][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-04-25 20:34:38,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:34:38,286][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.34%\n",
      "[ 2018-04-25 20:34:38,299][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:34:38,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=98.34%\n",
      "[ 2018-04-25 20:34:38,324][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:34:38,335][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-04-25 20:34:38,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=97.59%\n",
      "[ 2018-04-25 20:34:38,338][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.58%\n",
      "[ 2018-04-25 20:34:38,340][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=97.84%\n",
      "[ 2018-04-25 20:34:38,341][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=97.87%\n",
      "[ 2018-04-25 20:34:38,343][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:34:38,944][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-04-25 20:34:39,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-04-25 20:34:40,526][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:34:41,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-04-25 20:34:42,097][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.34%\n",
      "[ 2018-04-25 20:34:43,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-04-25 20:34:43,783][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:34:44,584][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=99.17%\n",
      "[ 2018-04-25 20:34:45,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-04-25 20:34:46,170][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=97.50%\n",
      "[ 2018-04-25 20:34:46,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=97.80%\n",
      "[ 2018-04-25 20:34:46,320][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=97.97%\n",
      "[ 2018-04-25 20:34:46,986][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-04-25 20:34:47,800][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-04-25 20:34:48,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=97.51%\n",
      "[ 2018-04-25 20:34:49,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=98.34%\n",
      "[ 2018-04-25 20:34:50,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.34%\n",
      "[ 2018-04-25 20:34:51,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=98.34%\n",
      "[ 2018-04-25 20:34:51,964][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=97.93%\n",
      "[ 2018-04-25 20:34:52,725][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=97.51%\n",
      "[ 2018-04-25 20:34:53,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:34:54,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=98.75%\n",
      "[ 2018-04-25 20:34:54,526][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=98.01%\n",
      "[ 2018-04-25 20:34:54,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.97%\n",
      "[ 2018-04-25 20:34:54,557][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-04-25 20:34:54,577][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-04-25 20:34:54,595][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:34:54,611][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-04-25 20:34:54,625][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:34:54,638][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-04-25 20:34:54,652][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:34:54,664][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-04-25 20:34:54,677][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=96.68%\n",
      "[ 2018-04-25 20:34:54,689][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=97.50%\n",
      "[ 2018-04-25 20:34:54,691][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=97.68%\n",
      "[ 2018-04-25 20:34:54,692][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:34:54,694][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=97.88%\n",
      "[ 2018-04-25 20:34:54,695][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=97.87%\n",
      "[ 2018-04-25 20:34:54,697][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:34:55,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-04-25 20:34:56,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-04-25 20:34:57,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:34:57,968][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-04-25 20:34:58,758][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-04-25 20:34:59,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-04-25 20:35:00,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=97.51%\n",
      "[ 2018-04-25 20:35:01,280][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-04-25 20:35:02,112][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=98.76%\n",
      "[ 2018-04-25 20:35:02,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=97.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:35:03,044][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=97.84%\n",
      "[ 2018-04-25 20:35:03,046][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=97.97%\n",
      "[ 2018-04-25 20:35:03,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-04-25 20:35:04,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-04-25 20:35:05,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-04-25 20:35:06,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-04-25 20:35:07,018][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:35:07,812][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=98.76%\n",
      "[ 2018-04-25 20:35:08,587][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=97.51%\n",
      "[ 2018-04-25 20:35:09,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=97.10%\n",
      "[ 2018-04-25 20:35:10,246][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=98.34%\n",
      "[ 2018-04-25 20:35:11,032][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-04-25 20:35:11,189][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=97.93%\n",
      "[ 2018-04-25 20:35:11,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:35:11,220][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-04-25 20:35:11,237][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-04-25 20:35:11,254][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-04-25 20:35:11,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-04-25 20:35:11,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:35:11,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-04-25 20:35:11,310][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=98.76%\n",
      "[ 2018-04-25 20:35:11,322][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-04-25 20:35:11,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:35:11,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=97.50%\n",
      "[ 2018-04-25 20:35:11,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-04-25 20:35:11,349][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:35:11,351][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=97.97%\n",
      "[ 2018-04-25 20:35:11,352][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=97.97%\n",
      "[ 2018-04-25 20:35:11,354][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:35:11,931][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-04-25 20:35:12,757][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-04-25 20:35:13,602][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:35:14,376][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-04-25 20:35:15,154][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-04-25 20:35:15,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=99.17%\n",
      "[ 2018-04-25 20:35:16,728][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:35:17,638][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-04-25 20:35:18,451][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:35:19,263][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-04-25 20:35:19,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=98.01%\n",
      "[ 2018-04-25 20:35:19,419][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:35:20,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-04-25 20:35:20,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-04-25 20:35:21,714][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=98.76%\n",
      "[ 2018-04-25 20:35:22,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=98.76%\n",
      "[ 2018-04-25 20:35:23,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=98.34%\n",
      "[ 2018-04-25 20:35:24,074][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-04-25 20:35:24,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:35:25,633][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=98.76%\n",
      "[ 2018-04-25 20:35:26,546][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=97.10%\n",
      "[ 2018-04-25 20:35:27,342][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=97.50%\n",
      "[ 2018-04-25 20:35:27,494][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=97.97%\n",
      "[ 2018-04-25 20:35:27,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:35:27,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-04-25 20:35:27,542][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-04-25 20:35:27,559][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=97.10%\n",
      "[ 2018-04-25 20:35:27,574][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-04-25 20:35:27,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:35:27,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=98.76%\n",
      "[ 2018-04-25 20:35:27,616][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:35:27,629][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=98.76%\n",
      "[ 2018-04-25 20:35:27,641][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:35:27,653][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-04-25 20:35:27,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-04-25 20:35:27,657][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=97.77%\n",
      "[ 2018-04-25 20:35:27,658][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=97.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:35:27,660][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=97.97%\n",
      "[ 2018-04-25 20:35:27,662][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:35:28,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=98.35%\n",
      "[ 2018-04-25 20:35:29,081][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=98.34%\n",
      "[ 2018-04-25 20:35:29,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-04-25 20:35:30,564][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-04-25 20:35:31,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=98.34%\n",
      "[ 2018-04-25 20:35:32,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-04-25 20:35:33,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:35:33,921][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=98.34%\n",
      "[ 2018-04-25 20:35:34,715][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=98.76%\n",
      "[ 2018-04-25 20:35:35,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=97.08%\n",
      "[ 2018-04-25 20:35:35,714][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=97.93%\n",
      "[ 2018-04-25 20:35:35,716][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:35:36,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-04-25 20:35:37,254][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-04-25 20:35:38,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:35:38,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-04-25 20:35:39,778][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=98.34%\n",
      "[ 2018-04-25 20:35:40,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-04-25 20:35:41,333][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:35:42,136][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=97.10%\n",
      "[ 2018-04-25 20:35:42,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=99.17%\n",
      "[ 2018-04-25 20:35:43,753][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=98.33%\n",
      "[ 2018-04-25 20:35:43,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=97.97%\n",
      "[ 2018-04-25 20:35:43,911][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=97.97%\n",
      "[ 2018-04-25 20:35:43,942][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-04-25 20:35:43,975][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-04-25 20:35:43,999][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=99.59%\n",
      "[ 2018-04-25 20:35:44,016][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-04-25 20:35:44,033][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-04-25 20:35:44,047][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=97.10%\n",
      "[ 2018-04-25 20:35:44,061][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:35:44,074][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=97.51%\n",
      "[ 2018-04-25 20:35:44,086][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:35:44,099][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-04-25 20:35:44,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=97.84%\n",
      "[ 2018-04-25 20:35:44,102][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=97.77%\n",
      "[ 2018-04-25 20:35:44,104][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=97.97%\n",
      "[ 2018-04-25 20:35:44,105][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=97.97%\n",
      "[ 2018-04-25 20:35:44,111][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:35:44,691][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-04-25 20:35:45,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=98.34%\n",
      "[ 2018-04-25 20:35:46,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=97.10%\n",
      "[ 2018-04-25 20:35:47,177][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-04-25 20:35:47,959][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-04-25 20:35:48,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=96.68%\n",
      "[ 2018-04-25 20:35:49,531][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:35:50,359][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=98.76%\n",
      "[ 2018-04-25 20:35:51,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=98.34%\n",
      "[ 2018-04-25 20:35:52,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=98.33%\n",
      "[ 2018-04-25 20:35:52,169][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-04-25 20:35:52,171][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=97.97%\n",
      "[ 2018-04-25 20:35:52,796][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=98.35%\n",
      "[ 2018-04-25 20:35:53,680][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=96.68%\n",
      "[ 2018-04-25 20:35:54,443][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-04-25 20:35:55,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=96.68%\n",
      "[ 2018-04-25 20:35:56,036][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=99.17%\n",
      "[ 2018-04-25 20:35:56,885][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=97.10%\n",
      "[ 2018-04-25 20:35:57,695][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-04-25 20:35:58,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=99.17%\n",
      "[ 2018-04-25 20:35:59,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-04-25 20:36:00,074][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=97.08%\n",
      "[ 2018-04-25 20:36:00,224][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-04-25 20:36:00,226][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-04-25 20:36:00,256][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=96.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:36:00,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-04-25 20:36:00,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=98.76%\n",
      "[ 2018-04-25 20:36:00,311][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-04-25 20:36:00,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=99.17%\n",
      "[ 2018-04-25 20:36:00,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=97.10%\n",
      "[ 2018-04-25 20:36:00,357][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-04-25 20:36:00,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=98.34%\n",
      "[ 2018-04-25 20:36:00,383][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=97.10%\n",
      "[ 2018-04-25 20:36:00,395][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-04-25 20:36:00,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=97.76%\n",
      "[ 2018-04-25 20:36:00,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=97.77%\n",
      "[ 2018-04-25 20:36:00,399][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=97.88%\n",
      "[ 2018-04-25 20:36:00,401][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=97.87%\n",
      "[ 2018-04-25 20:36:00,402][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=4, accuracy_train=97.97%, accuracy_test=97.97%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:36:00,503][cascade_classifier.transform] X_groups_test.shape=[(1033, 21)]\n",
      "[ 2018-04-25 20:36:00,505][cascade_classifier.transform] group_dims=[21]\n",
      "[ 2018-04-25 20:36:00,508][cascade_classifier.transform] X_test.shape=(1033, 21)\n",
      "[ 2018-04-25 20:36:00,509][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(1033, 21)\n",
      "[ 2018-04-25 20:36:03,544][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:36:06,625][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(1033, 27)\n",
      "[ 2018-04-25 20:36:09,740][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(1033, 27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 97.967086 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6731 - acc: 0.9700     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.5048 - acc: 0.9700     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1775 - acc: 0.9700     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1349 - acc: 0.9700     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1338 - acc: 0.9700     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1336 - acc: 0.9700     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1334 - acc: 0.9700     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1326 - acc: 0.9700     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1319 - acc: 0.9700     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1315 - acc: 0.9700     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1311 - acc: 0.9700     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1310 - acc: 0.9700     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1301 - acc: 0.9700     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1297 - acc: 0.9700     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1290 - acc: 0.9700     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1287 - acc: 0.9700     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1276 - acc: 0.9700     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1270 - acc: 0.9700     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1268 - acc: 0.9700     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1262 - acc: 0.9700     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1254 - acc: 0.9700     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1244 - acc: 0.9700     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1237 - acc: 0.9700     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1230 - acc: 0.9700     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1222 - acc: 0.9700     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1215 - acc: 0.9700     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1209 - acc: 0.9700     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1196 - acc: 0.9700     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1188 - acc: 0.9700     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1178 - acc: 0.9700     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1167 - acc: 0.9700     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1156 - acc: 0.9700     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1147 - acc: 0.9700     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1131 - acc: 0.9700     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1118 - acc: 0.9700     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1104 - acc: 0.9700     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1094 - acc: 0.9700     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1076 - acc: 0.9700     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1061 - acc: 0.9700     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1048 - acc: 0.9700     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1034 - acc: 0.9700     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1016 - acc: 0.9700     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1001 - acc: 0.9700     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0985 - acc: 0.9700     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0973 - acc: 0.9700     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0957 - acc: 0.9700     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0946 - acc: 0.9700     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0936 - acc: 0.9700     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0933 - acc: 0.9700     - ETA: 0s - loss: 0.0938 - acc: 0.970\n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0922 - acc: 0.9700     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0918 - acc: 0.9700     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0903 - acc: 0.9700     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0904 - acc: 0.9700     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0901 - acc: 0.9700     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0896 - acc: 0.9700     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0901 - acc: 0.9700     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0891 - acc: 0.9700     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0892 - acc: 0.9700     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0898 - acc: 0.9700     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0883 - acc: 0.9700     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0885 - acc: 0.9700     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0881 - acc: 0.9700     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0883 - acc: 0.9700     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0881 - acc: 0.9700     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0880 - acc: 0.9700     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0880 - acc: 0.9700     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0879 - acc: 0.9700     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0880 - acc: 0.9700     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0875 - acc: 0.9700     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0875 - acc: 0.9700     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0873 - acc: 0.9700     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0869 - acc: 0.9700     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0884 - acc: 0.9700     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0875 - acc: 0.9700     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0866 - acc: 0.9700     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9700     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0870 - acc: 0.9700     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0861 - acc: 0.9700     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9700     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0864 - acc: 0.9700     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0855 - acc: 0.9700     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0861 - acc: 0.9700     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0850 - acc: 0.9700     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0852 - acc: 0.9700     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0848 - acc: 0.9700     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0845 - acc: 0.9700     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0836 - acc: 0.9700     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0830 - acc: 0.9700     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0828 - acc: 0.9700     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0824 - acc: 0.9700     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0824 - acc: 0.9700     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0811 - acc: 0.9700     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0810 - acc: 0.9700     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0805 - acc: 0.9700     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0795 - acc: 0.9700     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0786 - acc: 0.9700     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0780 - acc: 0.9700     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0771 - acc: 0.9700     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0758 - acc: 0.9700     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0750 - acc: 0.9700     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6716 - acc: 0.9594     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4487 - acc: 0.9719     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1420 - acc: 0.9719     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1279 - acc: 0.9719     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1275 - acc: 0.9719     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1270 - acc: 0.9719     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1264 - acc: 0.9719     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1259 - acc: 0.9719     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1255 - acc: 0.9719     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1251 - acc: 0.9719     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1241 - acc: 0.9719     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1242 - acc: 0.9719     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - ETA: 0s - loss: 0.1274 - acc: 0.970 - 0s - loss: 0.1232 - acc: 0.9719     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1228 - acc: 0.9719     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1225 - acc: 0.9719     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1214 - acc: 0.9719     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1205 - acc: 0.9719     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1199 - acc: 0.9719     - ETA: 0s - loss: 0.1129 - acc: 0.97\n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1191 - acc: 0.9719     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1191 - acc: 0.9719     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1183 - acc: 0.9719     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1172 - acc: 0.9719     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1163 - acc: 0.9719     - ETA: 0s - loss: 0.1329 - acc: 0.96\n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1157 - acc: 0.9719     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1145 - acc: 0.9719     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1136 - acc: 0.9719     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1129 - acc: 0.9719     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1122 - acc: 0.9719     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1106 - acc: 0.9719     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1099 - acc: 0.9719     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1082 - acc: 0.9719     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1068 - acc: 0.9719     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1055 - acc: 0.9719     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1039 - acc: 0.9719     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1024 - acc: 0.9719     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1007 - acc: 0.9719     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0990 - acc: 0.9719     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0975 - acc: 0.9719     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0954 - acc: 0.9719     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0937 - acc: 0.9719     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0930 - acc: 0.9719     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0912 - acc: 0.9719     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0891 - acc: 0.9719     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - ETA: 0s - loss: 0.0817 - acc: 0.975 - 0s - loss: 0.0884 - acc: 0.9719     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0875 - acc: 0.9719     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0864 - acc: 0.9719     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0853 - acc: 0.9719     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0857 - acc: 0.9719     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0843 - acc: 0.9719     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0845 - acc: 0.9719     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0839 - acc: 0.9719     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0830 - acc: 0.9719     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0835 - acc: 0.9719     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0826 - acc: 0.9719     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0829 - acc: 0.9719     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0828 - acc: 0.9719     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0828 - acc: 0.9719     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0819 - acc: 0.9719     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0825 - acc: 0.9719     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0821 - acc: 0.9719     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0826 - acc: 0.9719     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0819 - acc: 0.9719     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0822 - acc: 0.9719     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0819 - acc: 0.9719     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0815 - acc: 0.9719     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0816 - acc: 0.9719     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0818 - acc: 0.9719     - ETA: 0s - loss: 0.0578 - acc: 0.98\n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0818 - acc: 0.9719     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0815 - acc: 0.9719     \n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 0s - loss: 0.0817 - acc: 0.9719     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0816 - acc: 0.9719     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0812 - acc: 0.9719     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0809 - acc: 0.9719     - ETA: 0s - loss: 0.0755 - acc: 0.973\n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0818 - acc: 0.9719     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0808 - acc: 0.9719     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0811 - acc: 0.9719     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0795 - acc: 0.9719     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0808 - acc: 0.9719     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0796 - acc: 0.9719     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0801 - acc: 0.9719     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0800 - acc: 0.9719     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0794 - acc: 0.9719     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0786 - acc: 0.9719     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0786 - acc: 0.9719     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0782 - acc: 0.9719     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0779 - acc: 0.9719     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0773 - acc: 0.9719     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0777 - acc: 0.9719     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0773 - acc: 0.9719     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0761 - acc: 0.9719     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0757 - acc: 0.9719     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0754 - acc: 0.9719     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0747 - acc: 0.9719     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0744 - acc: 0.9719     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0746 - acc: 0.9719     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0732 - acc: 0.9719     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0719 - acc: 0.9719     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0721 - acc: 0.9719     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0709 - acc: 0.9719     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0700 - acc: 0.9719     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6618 - acc: 0.9553     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3121 - acc: 0.9696     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1372 - acc: 0.9696     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1354 - acc: 0.9696     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1349 - acc: 0.9696     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1342 - acc: 0.9696     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1338 - acc: 0.9696     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1326 - acc: 0.9696     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1319 - acc: 0.9696     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1312 - acc: 0.9696     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1306 - acc: 0.9696     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1294 - acc: 0.9696     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1285 - acc: 0.9696     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1278 - acc: 0.9696     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1266 - acc: 0.9696     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1259 - acc: 0.9696     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1249 - acc: 0.9696     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1239 - acc: 0.9696     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1230 - acc: 0.9696     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1211 - acc: 0.9696     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1198 - acc: 0.9696     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1188 - acc: 0.9696     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1169 - acc: 0.9696     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1154 - acc: 0.9696     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1134 - acc: 0.9696     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1120 - acc: 0.9696     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1099 - acc: 0.9696     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1073 - acc: 0.9696     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1043 - acc: 0.9696     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1021 - acc: 0.9696     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0995 - acc: 0.9696     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0976 - acc: 0.9696     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0953 - acc: 0.9696     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0934 - acc: 0.9696     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0927 - acc: 0.9696     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0910 - acc: 0.9696     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0900 - acc: 0.9696     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0899 - acc: 0.9696     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0893 - acc: 0.9696     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0887 - acc: 0.9696     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0881 - acc: 0.9696     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0883 - acc: 0.9696     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0885 - acc: 0.9696     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0867 - acc: 0.9696     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0888 - acc: 0.9696     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0880 - acc: 0.9696     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0873 - acc: 0.9696     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0881 - acc: 0.9696     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0881 - acc: 0.9696     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0871 - acc: 0.9696     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0872 - acc: 0.9696     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0869 - acc: 0.9696     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0866 - acc: 0.9696     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0864 - acc: 0.9696     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0864 - acc: 0.9696     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0873 - acc: 0.9696     - ETA: 0s - loss: 0.1012 - acc: 0.96\n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9696     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9696     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0861 - acc: 0.9696     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0874 - acc: 0.9696     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0860 - acc: 0.9696     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0860 - acc: 0.9696     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0858 - acc: 0.9696     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0854 - acc: 0.9696     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0852 - acc: 0.9696     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0851 - acc: 0.9696     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0851 - acc: 0.9696     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0846 - acc: 0.9696     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0842 - acc: 0.9696     - ETA: 0s - loss: 0.0745 - acc: 0.97\n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0835 - acc: 0.9696     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0836 - acc: 0.9696     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0829 - acc: 0.9696     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0822 - acc: 0.9696     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0805 - acc: 0.9696     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0829 - acc: 0.9696     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0803 - acc: 0.9696     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0790 - acc: 0.9696     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0804 - acc: 0.9696     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0780 - acc: 0.9696     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0770 - acc: 0.9696     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0758 - acc: 0.9696     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0742 - acc: 0.9696     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0730 - acc: 0.9696     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0722 - acc: 0.9696     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0713 - acc: 0.9696     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0704 - acc: 0.9696     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0692 - acc: 0.9696     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0689 - acc: 0.9696     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0682 - acc: 0.9696     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0663 - acc: 0.9774     - ETA: 0s - loss: 0.0784 - acc: 0.97\n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0669 - acc: 0.9756     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0659 - acc: 0.9774     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0645 - acc: 0.9783     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0639 - acc: 0.9779     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0640 - acc: 0.9774     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0635 - acc: 0.9783     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0625 - acc: 0.9793     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0635 - acc: 0.9797     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0625 - acc: 0.9783     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0616 - acc: 0.9783     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6775 - acc: 0.9613     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6469 - acc: 0.9733     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6179 - acc: 0.9733     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.5906 - acc: 0.9733     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.5647 - acc: 0.9733     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.5403 - acc: 0.9733     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.5172 - acc: 0.9733     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4954 - acc: 0.9733     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4749 - acc: 0.9733     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4555 - acc: 0.9733     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4372 - acc: 0.9733     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4200 - acc: 0.9733     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4037 - acc: 0.9733     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3884 - acc: 0.9733     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3740 - acc: 0.9733     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3603 - acc: 0.9733     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3475 - acc: 0.9733     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3353 - acc: 0.9733     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3239 - acc: 0.9733     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3131 - acc: 0.9733     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3029 - acc: 0.9733     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2932 - acc: 0.9733     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2841 - acc: 0.9733     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2755 - acc: 0.9733     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2674 - acc: 0.9733     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2597 - acc: 0.9733     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2524 - acc: 0.9733     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2455 - acc: 0.9733     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2390 - acc: 0.9733     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2328 - acc: 0.9733     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2270 - acc: 0.9733     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2215 - acc: 0.9733     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2162 - acc: 0.9733     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2113 - acc: 0.9733     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2066 - acc: 0.9733     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2021 - acc: 0.9733     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1979 - acc: 0.9733     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1939 - acc: 0.9733     \n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 0s - loss: 0.1901 - acc: 0.9733     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1865 - acc: 0.9733     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1830 - acc: 0.9733     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1798 - acc: 0.9733     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1767 - acc: 0.9733     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1738 - acc: 0.9733     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1710 - acc: 0.9733     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1684 - acc: 0.9733     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1659 - acc: 0.9733     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1635 - acc: 0.9733     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1612 - acc: 0.9733     - ETA: 0s - loss: 0.1580 - acc: 0.97\n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1591 - acc: 0.9733     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1571 - acc: 0.9733     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1552 - acc: 0.9733     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1533 - acc: 0.9733     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1516 - acc: 0.9733     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1500 - acc: 0.9733     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1484 - acc: 0.9733     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1469 - acc: 0.9733     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1455 - acc: 0.9733     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1442 - acc: 0.9733     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1429 - acc: 0.9733     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1417 - acc: 0.9733     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1406 - acc: 0.9733     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1395 - acc: 0.9733     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1385 - acc: 0.9733     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1375 - acc: 0.9733     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1366 - acc: 0.9733     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1358 - acc: 0.9733     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1349 - acc: 0.9733     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1342 - acc: 0.9733     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1335 - acc: 0.9733     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1328 - acc: 0.9733     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1321 - acc: 0.9733     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1315 - acc: 0.9733     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1310 - acc: 0.9733     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1304 - acc: 0.9733     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1299 - acc: 0.9733     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1294 - acc: 0.9733     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1290 - acc: 0.9733     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1286 - acc: 0.9733     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1282 - acc: 0.9733     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1278 - acc: 0.9733     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1275 - acc: 0.9733     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1271 - acc: 0.9733     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1268 - acc: 0.9733     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1266 - acc: 0.9733     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1263 - acc: 0.9733     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1261 - acc: 0.9733     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1258 - acc: 0.9733     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1256 - acc: 0.9733     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1254 - acc: 0.9733     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1252 - acc: 0.9733     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1251 - acc: 0.9733     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1249 - acc: 0.9733     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1248 - acc: 0.9733     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1246 - acc: 0.9733     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1245 - acc: 0.9733     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1244 - acc: 0.9733     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1243 - acc: 0.9733     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1242 - acc: 0.9733     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1241 - acc: 0.9733     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6748 - acc: 0.9553        \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.5737 - acc: 0.9700     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2734 - acc: 0.9700     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1402 - acc: 0.9700     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1343 - acc: 0.9700     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1340 - acc: 0.9700     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1336 - acc: 0.9700     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1332 - acc: 0.9700     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1330 - acc: 0.9700     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1325 - acc: 0.9700     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1323 - acc: 0.9700     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1317 - acc: 0.9700     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1313 - acc: 0.9700     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1310 - acc: 0.9700     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1303 - acc: 0.9700     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1299 - acc: 0.9700     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1295 - acc: 0.9700     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1291 - acc: 0.9700     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1290 - acc: 0.9700     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1281 - acc: 0.9700     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1285 - acc: 0.9700     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1274 - acc: 0.9700     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1269 - acc: 0.9700     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1261 - acc: 0.9700     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1259 - acc: 0.9700     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1253 - acc: 0.9700     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1247 - acc: 0.9700     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1244 - acc: 0.9700     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1236 - acc: 0.9700     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1232 - acc: 0.9700     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1225 - acc: 0.9700     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1221 - acc: 0.9700     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1211 - acc: 0.9700     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1205 - acc: 0.9700     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1199 - acc: 0.9700     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1193 - acc: 0.9700     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1184 - acc: 0.9700     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1179 - acc: 0.9700     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1170 - acc: 0.9700     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1161 - acc: 0.9700     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1153 - acc: 0.9700     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1141 - acc: 0.9700     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1133 - acc: 0.9700     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1123 - acc: 0.9700     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1113 - acc: 0.9700     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1105 - acc: 0.9700     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - ETA: 0s - loss: 0.0965 - acc: 0.974 - 0s - loss: 0.1090 - acc: 0.9700     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1079 - acc: 0.9700     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1069 - acc: 0.9700     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1055 - acc: 0.9700     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1039 - acc: 0.9700     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1026 - acc: 0.9700     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1016 - acc: 0.9700     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1002 - acc: 0.9700     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0986 - acc: 0.9700     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0974 - acc: 0.9700     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0963 - acc: 0.9700     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0955 - acc: 0.9700     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0942 - acc: 0.9700     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0935 - acc: 0.9700     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0923 - acc: 0.9700     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0920 - acc: 0.9700     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0912 - acc: 0.9700     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0906 - acc: 0.9700     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0898 - acc: 0.9700     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0897 - acc: 0.9700     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0890 - acc: 0.9700     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0890 - acc: 0.9700     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0885 - acc: 0.9700     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0883 - acc: 0.9700     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0885 - acc: 0.9700     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0878 - acc: 0.9700     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0880 - acc: 0.9700     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0881 - acc: 0.9700     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0874 - acc: 0.9700     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0880 - acc: 0.9700     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0874 - acc: 0.9700     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0874 - acc: 0.9700     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0875 - acc: 0.9700     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0871 - acc: 0.9700     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0871 - acc: 0.9700     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0867 - acc: 0.9700     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0873 - acc: 0.9700     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0869 - acc: 0.9700     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0869 - acc: 0.9700     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0872 - acc: 0.9700     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0869 - acc: 0.9700     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0867 - acc: 0.9700     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0867 - acc: 0.9700     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9700     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0867 - acc: 0.9700     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0867 - acc: 0.9700     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0868 - acc: 0.9700     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0864 - acc: 0.9700     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0874 - acc: 0.9700     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0866 - acc: 0.9700     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0870 - acc: 0.9700     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0871 - acc: 0.9700     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0863 - acc: 0.9700     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0863 - acc: 0.9700     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6528 - acc: 0.9714     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.2570 - acc: 0.9714     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1303 - acc: 0.9714     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1300 - acc: 0.9714     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1286 - acc: 0.9714     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1281 - acc: 0.9714     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1275 - acc: 0.9714     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1264 - acc: 0.9714     \n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 0s - loss: 0.1260 - acc: 0.9714     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1252 - acc: 0.9714     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1240 - acc: 0.9714     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1231 - acc: 0.9714     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1226 - acc: 0.9714     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1219 - acc: 0.9714     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1204 - acc: 0.9714     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1198 - acc: 0.9714     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1185 - acc: 0.9714     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1174 - acc: 0.9714     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1160 - acc: 0.9714     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1148 - acc: 0.9714     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1132 - acc: 0.9714     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1116 - acc: 0.9714     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1102 - acc: 0.9714     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1080 - acc: 0.9714     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1060 - acc: 0.9714     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1041 - acc: 0.9714     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1021 - acc: 0.9714     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0996 - acc: 0.9714     - ETA: 0s - loss: 0.0948 - acc: 0.973\n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0980 - acc: 0.9714     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0948 - acc: 0.9714     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0930 - acc: 0.9714     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0911 - acc: 0.9714     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0896 - acc: 0.9714     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0884 - acc: 0.9714     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0876 - acc: 0.9714     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0873 - acc: 0.9714     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0861 - acc: 0.9714     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0851 - acc: 0.9714     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0857 - acc: 0.9714     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0853 - acc: 0.9714     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0857 - acc: 0.9714     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0846 - acc: 0.9714     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0852 - acc: 0.9714     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0846 - acc: 0.9714     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0846 - acc: 0.9714     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0836 - acc: 0.9714     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0834 - acc: 0.9714     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0834 - acc: 0.9714     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0836 - acc: 0.9714     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0840 - acc: 0.9714     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0830 - acc: 0.9714     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0836 - acc: 0.9714     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0823 - acc: 0.9714     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0826 - acc: 0.9714     - ETA: 0s - loss: 0.0789 - acc: 0.972\n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0822 - acc: 0.9714     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0818 - acc: 0.9714     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0810 - acc: 0.9714     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0802 - acc: 0.9714     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0804 - acc: 0.9714     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0791 - acc: 0.9714     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0785 - acc: 0.9714     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0777 - acc: 0.9714     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0762 - acc: 0.9714     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0754 - acc: 0.9714     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0752 - acc: 0.9714     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0724 - acc: 0.9714     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0716 - acc: 0.9714     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0711 - acc: 0.9714     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0700 - acc: 0.9714     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0679 - acc: 0.9714     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0670 - acc: 0.9714     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0655 - acc: 0.9714     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0651 - acc: 0.9714     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0647 - acc: 0.9714     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0626 - acc: 0.9714     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0621 - acc: 0.9756     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0631 - acc: 0.9802     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0613 - acc: 0.9788     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0608 - acc: 0.9811     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0593 - acc: 0.9797     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0590 - acc: 0.9811     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0588 - acc: 0.9811     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0589 - acc: 0.9806     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0581 - acc: 0.9802     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0569 - acc: 0.9816     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0567 - acc: 0.9825     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0576 - acc: 0.9816     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0576 - acc: 0.9829     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - ETA: 0s - loss: 0.0529 - acc: 0.984 - 0s - loss: 0.0572 - acc: 0.9829     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0560 - acc: 0.9825     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0563 - acc: 0.9829     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0568 - acc: 0.9825     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0563 - acc: 0.9829     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0556 - acc: 0.9829     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0560 - acc: 0.9829     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0558 - acc: 0.9825     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0567 - acc: 0.9829     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0568 - acc: 0.9825     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0560 - acc: 0.9834     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0551 - acc: 0.9820     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6690 - acc: 0.9553     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4285 - acc: 0.9691     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1472 - acc: 0.9691     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1373 - acc: 0.9691     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1367 - acc: 0.9691     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1361 - acc: 0.9691     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1354 - acc: 0.9691     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1349 - acc: 0.9691     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1345 - acc: 0.9691     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1338 - acc: 0.9691     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1329 - acc: 0.9691     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1321 - acc: 0.9691     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1315 - acc: 0.9691     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1312 - acc: 0.9691     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1300 - acc: 0.9691     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1292 - acc: 0.9691     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1287 - acc: 0.9691     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1278 - acc: 0.9691     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1270 - acc: 0.9691     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1268 - acc: 0.9691     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1248 - acc: 0.9691     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1242 - acc: 0.9691     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1229 - acc: 0.9691     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1218 - acc: 0.9691     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1208 - acc: 0.9691     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1196 - acc: 0.9691     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1183 - acc: 0.9691     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1170 - acc: 0.9691     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1153 - acc: 0.9691     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1135 - acc: 0.9691     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1118 - acc: 0.9691     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1096 - acc: 0.9691     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1078 - acc: 0.9691     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1057 - acc: 0.9691     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1030 - acc: 0.9691     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1014 - acc: 0.9691     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0992 - acc: 0.9691     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0972 - acc: 0.9691     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0951 - acc: 0.9691     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0937 - acc: 0.9691     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0925 - acc: 0.9691     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0913 - acc: 0.9691     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0904 - acc: 0.9691     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0890 - acc: 0.9691     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0894 - acc: 0.9691     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0884 - acc: 0.9691     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0878 - acc: 0.9691     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0876 - acc: 0.9691     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0875 - acc: 0.9691     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0870 - acc: 0.9691     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0871 - acc: 0.9691     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0866 - acc: 0.9691     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0871 - acc: 0.9691     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0874 - acc: 0.9691     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9691     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0864 - acc: 0.9691     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0860 - acc: 0.9691     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0857 - acc: 0.9691     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0860 - acc: 0.9691     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0863 - acc: 0.9691     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0855 - acc: 0.9691     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0861 - acc: 0.9691     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0863 - acc: 0.9691     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - ETA: 0s - loss: 0.0881 - acc: 0.966 - 0s - loss: 0.0851 - acc: 0.9691     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0851 - acc: 0.9691     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0847 - acc: 0.9691     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0843 - acc: 0.9691     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0840 - acc: 0.9691     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0837 - acc: 0.9691     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0834 - acc: 0.9691     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0828 - acc: 0.9691     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0829 - acc: 0.9691     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0816 - acc: 0.9691     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0814 - acc: 0.9691     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0801 - acc: 0.9691     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0796 - acc: 0.9691     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0787 - acc: 0.9691     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0779 - acc: 0.9691     \n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 0s - loss: 0.0771 - acc: 0.9691     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0762 - acc: 0.9691     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0748 - acc: 0.9691     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0739 - acc: 0.9691     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0721 - acc: 0.9691     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0717 - acc: 0.9691     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0701 - acc: 0.9691     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0687 - acc: 0.9691     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0677 - acc: 0.9691     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0663 - acc: 0.9691     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0657 - acc: 0.9691     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0648 - acc: 0.9756     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0639 - acc: 0.9769     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0633 - acc: 0.9760     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0629 - acc: 0.9779     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0628 - acc: 0.9765     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0616 - acc: 0.9797     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0612 - acc: 0.9783     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0609 - acc: 0.9783     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0604 - acc: 0.9788     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0601 - acc: 0.9788     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0596 - acc: 0.9774     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6712 - acc: 0.9714     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.4409 - acc: 0.9714     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1427 - acc: 0.9714     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1290 - acc: 0.9714     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1289 - acc: 0.9714     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1281 - acc: 0.9714     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1278 - acc: 0.9714     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1270 - acc: 0.9714     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1264 - acc: 0.9714     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1262 - acc: 0.9714     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1256 - acc: 0.9714     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1248 - acc: 0.9714     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1239 - acc: 0.9714     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1234 - acc: 0.9714     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1228 - acc: 0.9714     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1220 - acc: 0.9714     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1213 - acc: 0.9714     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1207 - acc: 0.9714     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1199 - acc: 0.9714     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1191 - acc: 0.9714     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1184 - acc: 0.9714     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1173 - acc: 0.9714     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1166 - acc: 0.9714     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1154 - acc: 0.9714     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1146 - acc: 0.9714     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1135 - acc: 0.9714     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1123 - acc: 0.9714     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1115 - acc: 0.9714     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1102 - acc: 0.9714     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1087 - acc: 0.9714     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1072 - acc: 0.9714     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1063 - acc: 0.9714     - ETA: 0s - loss: 0.1008 - acc: 0.973\n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1044 - acc: 0.9714     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1025 - acc: 0.9714     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1008 - acc: 0.9714     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0988 - acc: 0.9714     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0971 - acc: 0.9714     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0955 - acc: 0.9714     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0930 - acc: 0.9714     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0913 - acc: 0.9714     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0898 - acc: 0.9714     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0876 - acc: 0.9714     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0872 - acc: 0.9714     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0857 - acc: 0.9714     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0847 - acc: 0.9714     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0837 - acc: 0.9714     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0834 - acc: 0.9714     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0823 - acc: 0.9714     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0828 - acc: 0.9714     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0819 - acc: 0.9714     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0811 - acc: 0.9714     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0808 - acc: 0.9714     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0815 - acc: 0.9714     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0807 - acc: 0.9714     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0798 - acc: 0.9714     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0814 - acc: 0.9714     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0800 - acc: 0.9714     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0796 - acc: 0.9714     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0807 - acc: 0.9714     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0807 - acc: 0.9714     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0795 - acc: 0.9714     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0794 - acc: 0.9714     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0792 - acc: 0.9714     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0792 - acc: 0.9714     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0787 - acc: 0.9714     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0794 - acc: 0.9714     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0788 - acc: 0.9714     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0789 - acc: 0.9714     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0791 - acc: 0.9714     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0782 - acc: 0.9714     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0791 - acc: 0.9714     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0781 - acc: 0.9714     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0785 - acc: 0.9714     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0781 - acc: 0.9714     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0780 - acc: 0.9714     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0778 - acc: 0.9714     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0773 - acc: 0.9714     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0772 - acc: 0.9714     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0772 - acc: 0.9714     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0768 - acc: 0.9714     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0766 - acc: 0.9714     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0764 - acc: 0.9714     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0759 - acc: 0.9714     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0761 - acc: 0.9714     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0754 - acc: 0.9714     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0749 - acc: 0.9714     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0747 - acc: 0.9714     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0731 - acc: 0.9714     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0729 - acc: 0.9714     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0721 - acc: 0.9714     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0711 - acc: 0.9714     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0698 - acc: 0.9714     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0692 - acc: 0.9714     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0682 - acc: 0.9714     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0670 - acc: 0.9714     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0663 - acc: 0.9714     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0655 - acc: 0.9705     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0636 - acc: 0.9737     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0628 - acc: 0.9756     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - ETA: 0s - loss: 0.0558 - acc: 0.975 - 0s - loss: 0.0617 - acc: 0.9760     \n",
      " 32/241 [==>...........................] - ETA: 0sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6634 - acc: 0.9677     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3360 - acc: 0.9677     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1431 - acc: 0.9677     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1419 - acc: 0.9677     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1414 - acc: 0.9677     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1403 - acc: 0.9677     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1395 - acc: 0.9677     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1385 - acc: 0.9677     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1378 - acc: 0.9677     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1369 - acc: 0.9677     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1361 - acc: 0.9677     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1352 - acc: 0.9677     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1342 - acc: 0.9677     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1332 - acc: 0.9677     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1328 - acc: 0.9677     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1324 - acc: 0.9677     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1297 - acc: 0.9677     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1288 - acc: 0.9677     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1272 - acc: 0.9677     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1258 - acc: 0.9677     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1246 - acc: 0.9677     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1228 - acc: 0.9677     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1209 - acc: 0.9677     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1189 - acc: 0.9677     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1169 - acc: 0.9677     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1144 - acc: 0.9677     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1120 - acc: 0.9677     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1091 - acc: 0.9677     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1064 - acc: 0.9677     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1040 - acc: 0.9677     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1016 - acc: 0.9677     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0996 - acc: 0.9677     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0968 - acc: 0.9677     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0948 - acc: 0.9677     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0946 - acc: 0.9677     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0929 - acc: 0.9677     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0914 - acc: 0.9677     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0918 - acc: 0.9677     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0913 - acc: 0.9677     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0905 - acc: 0.9677     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0904 - acc: 0.9677     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0895 - acc: 0.9677     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0901 - acc: 0.9677     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0899 - acc: 0.9677     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0894 - acc: 0.9677     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0894 - acc: 0.9677     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0896 - acc: 0.9677     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0894 - acc: 0.9677     \n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 0s - loss: 0.0894 - acc: 0.9677     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0887 - acc: 0.9677     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0898 - acc: 0.9677     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0888 - acc: 0.9677     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0890 - acc: 0.9677     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0893 - acc: 0.9677     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0894 - acc: 0.9677     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0882 - acc: 0.9677     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0877 - acc: 0.9677     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0891 - acc: 0.9677     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0873 - acc: 0.9677     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0870 - acc: 0.9677     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0869 - acc: 0.9677     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9677     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0866 - acc: 0.9677     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0858 - acc: 0.9677     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0855 - acc: 0.9677     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0843 - acc: 0.9677     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0852 - acc: 0.9677     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0850 - acc: 0.9677     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0830 - acc: 0.9677     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0827 - acc: 0.9677     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0818 - acc: 0.9677     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0801 - acc: 0.9677     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0792 - acc: 0.9677     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0788 - acc: 0.9677     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0780 - acc: 0.9677     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0757 - acc: 0.9677     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0743 - acc: 0.9677     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0740 - acc: 0.9677     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0722 - acc: 0.9677     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0708 - acc: 0.9677     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0703 - acc: 0.9677     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0685 - acc: 0.9677     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0676 - acc: 0.9677     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0666 - acc: 0.9719     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0668 - acc: 0.9751     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0650 - acc: 0.9769     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0640 - acc: 0.9765     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0653 - acc: 0.9779     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0627 - acc: 0.9760     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0630 - acc: 0.9779     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0626 - acc: 0.9783     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0619 - acc: 0.9783     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0612 - acc: 0.9802     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0607 - acc: 0.9788     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0613 - acc: 0.9811     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0609 - acc: 0.9797     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0605 - acc: 0.9806     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0596 - acc: 0.9816     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0593 - acc: 0.9811     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0594 - acc: 0.9802     \n",
      " 32/241 [==>...........................] - ETA: 1sEpoch 1/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.6659 - acc: 0.9654     \n",
      "Epoch 2/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.3706 - acc: 0.9710     \n",
      "Epoch 3/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1355 - acc: 0.9710     \n",
      "Epoch 4/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1311 - acc: 0.9710     \n",
      "Epoch 5/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1308 - acc: 0.9710     \n",
      "Epoch 6/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1303 - acc: 0.9710     \n",
      "Epoch 7/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1299 - acc: 0.9710     \n",
      "Epoch 8/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1291 - acc: 0.9710     \n",
      "Epoch 9/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1283 - acc: 0.9710     \n",
      "Epoch 10/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1278 - acc: 0.9710     \n",
      "Epoch 11/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1270 - acc: 0.9710     \n",
      "Epoch 12/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1264 - acc: 0.9710     \n",
      "Epoch 13/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1260 - acc: 0.9710     \n",
      "Epoch 14/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1249 - acc: 0.9710     \n",
      "Epoch 15/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1242 - acc: 0.9710     \n",
      "Epoch 16/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1237 - acc: 0.9710     \n",
      "Epoch 17/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1229 - acc: 0.9710     \n",
      "Epoch 18/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1218 - acc: 0.9710     \n",
      "Epoch 19/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1216 - acc: 0.9710     \n",
      "Epoch 20/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1205 - acc: 0.9710     \n",
      "Epoch 21/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1192 - acc: 0.9710     \n",
      "Epoch 22/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1182 - acc: 0.9710     \n",
      "Epoch 23/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1171 - acc: 0.9710     \n",
      "Epoch 24/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1162 - acc: 0.9710     \n",
      "Epoch 25/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1149 - acc: 0.9710     \n",
      "Epoch 26/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1137 - acc: 0.9710     \n",
      "Epoch 27/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1121 - acc: 0.9710     \n",
      "Epoch 28/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1111 - acc: 0.9710     \n",
      "Epoch 29/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1095 - acc: 0.9710     \n",
      "Epoch 30/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1077 - acc: 0.9710     \n",
      "Epoch 31/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1061 - acc: 0.9710     \n",
      "Epoch 32/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1041 - acc: 0.9710     \n",
      "Epoch 33/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.1017 - acc: 0.9710     \n",
      "Epoch 34/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0997 - acc: 0.9710     \n",
      "Epoch 35/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0978 - acc: 0.9710     \n",
      "Epoch 36/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0963 - acc: 0.9710     \n",
      "Epoch 37/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0942 - acc: 0.9710     \n",
      "Epoch 38/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0925 - acc: 0.9710     \n",
      "Epoch 39/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0911 - acc: 0.9710     \n",
      "Epoch 40/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0906 - acc: 0.9710     \n",
      "Epoch 41/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0896 - acc: 0.9710     \n",
      "Epoch 42/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0886 - acc: 0.9710     \n",
      "Epoch 43/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0877 - acc: 0.9710     \n",
      "Epoch 44/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0876 - acc: 0.9710     \n",
      "Epoch 45/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0868 - acc: 0.9710     \n",
      "Epoch 46/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0863 - acc: 0.9710     \n",
      "Epoch 47/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0862 - acc: 0.9710     \n",
      "Epoch 48/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0872 - acc: 0.9710     \n",
      "Epoch 49/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0865 - acc: 0.9710     \n",
      "Epoch 50/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0861 - acc: 0.9710     \n",
      "Epoch 51/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0864 - acc: 0.9710     \n",
      "Epoch 52/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0855 - acc: 0.9710     \n",
      "Epoch 53/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0855 - acc: 0.9710     \n",
      "Epoch 54/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0853 - acc: 0.9710     \n",
      "Epoch 55/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0852 - acc: 0.9710     \n",
      "Epoch 56/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0850 - acc: 0.9710     \n",
      "Epoch 57/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0857 - acc: 0.9710     \n",
      "Epoch 58/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0850 - acc: 0.9710     \n",
      "Epoch 59/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0849 - acc: 0.9710     \n",
      "Epoch 60/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0846 - acc: 0.9710     \n",
      "Epoch 61/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0863 - acc: 0.9710     \n",
      "Epoch 62/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0867 - acc: 0.9710     \n",
      "Epoch 63/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0847 - acc: 0.9710     \n",
      "Epoch 64/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0842 - acc: 0.9710     \n",
      "Epoch 65/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0841 - acc: 0.9710     \n",
      "Epoch 66/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0848 - acc: 0.9710     \n",
      "Epoch 67/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0844 - acc: 0.9710     \n",
      "Epoch 68/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0839 - acc: 0.9710     \n",
      "Epoch 69/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0841 - acc: 0.9710     \n",
      "Epoch 70/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0839 - acc: 0.9710     \n",
      "Epoch 71/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0835 - acc: 0.9710     \n",
      "Epoch 72/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0833 - acc: 0.9710     \n",
      "Epoch 73/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0830 - acc: 0.9710     \n",
      "Epoch 74/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0831 - acc: 0.9710     \n",
      "Epoch 75/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0820 - acc: 0.9710     \n",
      "Epoch 76/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0820 - acc: 0.9710     \n",
      "Epoch 77/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0810 - acc: 0.9710     \n",
      "Epoch 78/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0806 - acc: 0.9710     \n",
      "Epoch 79/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0810 - acc: 0.9710     \n",
      "Epoch 80/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0795 - acc: 0.9710     \n",
      "Epoch 81/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0790 - acc: 0.9710     \n",
      "Epoch 82/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0783 - acc: 0.9710     \n",
      "Epoch 83/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0773 - acc: 0.9710     \n",
      "Epoch 84/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0764 - acc: 0.9710     \n",
      "Epoch 85/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0763 - acc: 0.9710     \n",
      "Epoch 86/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0746 - acc: 0.9710     \n",
      "Epoch 87/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0735 - acc: 0.9710     \n",
      "Epoch 88/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0718 - acc: 0.9710     \n",
      "Epoch 89/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0706 - acc: 0.9710     \n",
      "Epoch 90/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0694 - acc: 0.9710     \n",
      "Epoch 91/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0685 - acc: 0.9710     \n",
      "Epoch 92/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0669 - acc: 0.9710     \n",
      "Epoch 93/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0657 - acc: 0.9710     \n",
      "Epoch 94/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0642 - acc: 0.9710     \n",
      "Epoch 95/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0625 - acc: 0.9710     \n",
      "Epoch 96/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0617 - acc: 0.9710     \n",
      "Epoch 97/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0614 - acc: 0.9765     \n",
      "Epoch 98/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0600 - acc: 0.9765     \n",
      "Epoch 99/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0594 - acc: 0.9779     \n",
      "Epoch 100/100\n",
      "2169/2169 [==============================] - 0s - loss: 0.0588 - acc: 0.9797     \n",
      " 32/241 [==>...........................] - ETA: 1sAccuracy mean: 0.970539419236\n",
      "Accuracy variance: 0.012231869667\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 96.321394 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.579864 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.289448 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 96.708616 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 93.901258 %\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
